                      
"""
å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†æè„šæœ¬
æ”¯æŒå››ç±»åˆ¤æ–­æµç¨‹ï¼š
1. è·¯å¾„çº¦æŸç­‰ä»·ä¸”ç¨‹åºè¾“å‡ºç›¸åŒ â†’ ç­‰ä»·
2. è·¯å¾„çº¦æŸä¸ç­‰ä»·ä½†ç¨‹åºè¾“å‡ºç›¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆçº¦æŸï¼‰
3. è·¯å¾„çº¦æŸç­‰ä»·ä½†ç¨‹åºè¾“å‡ºä¸ç­‰ä»· â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆè¾“å‡ºï¼‰
4. è·¯å¾„çº¦æŸä¸ç­‰ä»·ä¸”ç¨‹åºè¾“å‡ºä¸ç­‰ä»· â†’ ä¸ç­‰ä»·

å¯¹æ‰€æœ‰æˆåŠŸç”Ÿæˆçº¦æŸæ–‡ä»¶çš„ç¨‹åºè¿›è¡Œç­‰ä»·æ€§åˆ†æ
åˆ†åˆ«åˆ†æEqï¼ˆç­‰ä»·ï¼‰å’ŒNEqï¼ˆä¸ç­‰ä»·ï¼‰ç¨‹åºå¯¹
"""

import os
import glob
import subprocess
import time
from pathlib import Path

class EnhancedBatchEquivalenceAnalyzer:
    def __init__(self, base_dir="/root/ardiff/symbolic_analysis"):
        self.base_dir = Path(base_dir)
        
    def find_program_pairs(self):
        """æŸ¥æ‰¾æ‰€æœ‰æœ‰çº¦æŸæ–‡ä»¶çš„ç¨‹åºå¯¹"""
                  
        constraint_files = glob.glob(str(self.base_dir / "benchmarks" / "**" / "*_path_*.txt"), recursive=True)
        
                   
        program_dirs = set()
        for cf in constraint_files:
            program_dir = os.path.dirname(cf)
            program_dirs.add(program_dir)
        
        print(f"ğŸ” å‘ç° {len(program_dirs)} ä¸ªæœ‰çº¦æŸæ–‡ä»¶çš„ç¨‹åºç›®å½•")
        
                      
        eq_pairs = []
        neq_pairs = []
        skipped_dirs = []
        
        for prog_dir in sorted(program_dirs):
                                 
            newv_files = glob.glob(os.path.join(prog_dir, "symbolic_newV_path_*.txt"))
            oldv_files = glob.glob(os.path.join(prog_dir, "symbolic_oldV_path_*.txt"))
            
            if newv_files and oldv_files:
                            
                if "/Eq/" in prog_dir or prog_dir.endswith("/Eq"):
                    eq_pairs.append({
                        'dir': prog_dir,
                        'newV_prefix': os.path.join(prog_dir, "symbolic_newV_path_"),
                        'oldV_prefix': os.path.join(prog_dir, "symbolic_oldV_path_"),
                        'newV_count': len(newv_files),
                        'oldV_count': len(oldv_files)
                    })
                elif "/NEq/" in prog_dir or prog_dir.endswith("/NEq"):
                    neq_pairs.append({
                        'dir': prog_dir,
                        'newV_prefix': os.path.join(prog_dir, "symbolic_newV_path_"),
                        'oldV_prefix': os.path.join(prog_dir, "symbolic_oldV_path_"),
                        'newV_count': len(newv_files),
                        'oldV_count': len(oldv_files)
                    })
                else:
                                       
                    print(f"  ğŸ” è·³è¿‡éEq/NEqç›®å½•: {os.path.relpath(prog_dir, self.base_dir)}")
                    skipped_dirs.append(prog_dir)
            else:
                                  
                missing = []
                if not newv_files:
                    missing.append("newV")
                if not oldv_files:
                    missing.append("oldV")
                print(f"  âš ï¸  ç¼ºå°‘çº¦æŸæ–‡ä»¶: {os.path.relpath(prog_dir, self.base_dir)} (ç¼ºå°‘: {', '.join(missing)})")
                skipped_dirs.append(prog_dir)
        
        print(f"ğŸ¯ åˆ†ç±»ç»“æœ:")
        print(f"  Eqç¨‹åºå¯¹: {len(eq_pairs)}")
        print(f"  NEqç¨‹åºå¯¹: {len(neq_pairs)}")
        print(f"  è·³è¿‡çš„ç›®å½•: {len(skipped_dirs)}")
        
        return eq_pairs, neq_pairs
    
    def parse_enhanced_results(self, output_lines):
        """è§£æå¢å¼ºç‰ˆåˆ†æç»“æœ"""
        result = {
            "equivalent_pairs": 0,
            "suspicious_constraint_pairs": 0,
            "suspicious_output_pairs": 0,
            "non_equivalent_pairs": 0,
            "program_equivalent": False,
            "total_analysis_pairs": 0
        }
        
        for line in output_lines:
            line = line.strip()
            
                    
            if "âœ… ç­‰ä»·è·¯å¾„å¯¹:" in line:
                try:
                    result["equivalent_pairs"] = int(line.split(":")[1].strip())
                except:
                    pass
            elif "âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ:" in line:
                try:
                    result["suspicious_constraint_pairs"] = int(line.split(":")[1].strip())
                except:
                    pass
            elif "âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º:" in line:
                try:
                    result["suspicious_output_pairs"] = int(line.split(":")[1].strip())
                except:
                    pass
            elif "âŒ ä¸ç­‰ä»·è·¯å¾„å¯¹:" in line:
                try:
                    result["non_equivalent_pairs"] = int(line.split(":")[1].strip())
                except:
                    pass
            elif "ç¨‹åºç­‰ä»·æ€§:" in line:
                result["program_equivalent"] = "âœ… ç­‰ä»·" in line
            elif "æ€»åˆ†æè·¯å¾„å¯¹:" in line:
                try:
                    result["total_analysis_pairs"] = int(line.split(":")[1].strip())
                except:
                    pass
        
        return result
    
    def run_equivalence_analysis(self, program_dir, program_type):
        """å¯¹å•ä¸ªç¨‹åºå¯¹è¿è¡Œå¢å¼ºç‰ˆç­‰ä»·æ€§åˆ†æ"""
                
        newv_prefix = os.path.join(program_dir, "symbolic_newV_path_")
        oldv_prefix = os.path.join(program_dir, "symbolic_oldV_path_")
        
              
        output_file = os.path.join(program_dir, f"equivalence_analysis_{program_type}.txt")
        
        print(f"  ğŸ” åˆ†æ: {os.path.relpath(program_dir, self.base_dir)}")
        print(f"      è¾“å‡º: {os.path.relpath(output_file, self.base_dir)}")
        
              
        cmd = [
            "python3", "semantic_equivalence_analyzer.py",
            newv_prefix,                  
            oldv_prefix,                  
            "--output", output_file,
            "--timeout", "30000"         
        ]
        
        try:
            start_time = time.time()
            result = subprocess.run(
                cmd,
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=120          
            )
            elapsed_time = time.time() - start_time
            
            if result.returncode == 0:
                         
                output_lines = result.stdout.split('\n')
                enhanced_results = self.parse_enhanced_results(output_lines)
                
                         
                if enhanced_results["program_equivalent"]:
                    equivalence_status = "equivalent"
                elif enhanced_results["suspicious_constraint_pairs"] > 0:
                    equivalence_status = "suspicious_constraint"
                elif enhanced_results["suspicious_output_pairs"] > 0:
                    equivalence_status = "suspicious_output"
                else:
                    equivalence_status = "not_equivalent"
                
                print(f"      âœ… æˆåŠŸ - {equivalence_status} ({elapsed_time:.1f}s)")
                print(f"        ç­‰ä»·: {enhanced_results['equivalent_pairs']}, "
                      f"ç–‘ä¼¼çº¦æŸ: {enhanced_results['suspicious_constraint_pairs']}, "
                      f"ç–‘ä¼¼è¾“å‡º: {enhanced_results['suspicious_output_pairs']}, "
                      f"ä¸ç­‰ä»·: {enhanced_results['non_equivalent_pairs']}")
                
                return {
                    "status": "success", 
                    "equivalence_status": equivalence_status,
                    "enhanced_results": enhanced_results,
                    "time": elapsed_time,
                    "output_file": output_file
                }
            else:
                print(f"      âŒ å¤±è´¥ - é”™è¯¯ç : {result.returncode} ({elapsed_time:.1f}s)")
                if result.stderr:
                    print(f"      é”™è¯¯: {result.stderr[:100]}...")
                return {
                    "status": "failed", 
                    "error": result.stderr, 
                    "time": elapsed_time
                }
                
        except subprocess.TimeoutExpired:
            print(f"      â° è¶…æ—¶ (120s)")
            return {"status": "timeout", "time": 120}
        except Exception as e:
            print(f"      ğŸ’¥ å¼‚å¸¸: {str(e)}")
            return {"status": "exception", "error": str(e), "time": 0}
    
    def analyze_all_programs(self):
        """åˆ†ææ‰€æœ‰ç¨‹åº"""
        print("ğŸ§  å¼€å§‹å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†æ...")
        print("=" * 60)
        print("å››ç±»åˆ¤æ–­æµç¨‹:")
        print("  1ï¸âƒ£  çº¦æŸç­‰ä»·ä¸”è¾“å‡ºç›¸åŒ â†’ ç­‰ä»·")
        print("  2ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä½†è¾“å‡ºç›¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆçº¦æŸï¼‰")
        print("  3ï¸âƒ£  çº¦æŸç­‰ä»·ä½†è¾“å‡ºä¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆè¾“å‡ºï¼‰")
        print("  4ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä¸”è¾“å‡ºä¸åŒ â†’ ä¸ç­‰ä»·")
        print("=" * 60)
        
               
        eq_pairs, neq_pairs = self.find_program_pairs()
        
        print(f"\nğŸ“Š å‘ç°ç¨‹åºå¯¹:")
        print(f"  Eq (åº”è¯¥ç­‰ä»·): {len(eq_pairs)} ä¸ª")
        print(f"  NEq (åº”è¯¥ä¸ç­‰ä»·): {len(neq_pairs)} ä¸ª")
        print(f"  æ€»è®¡: {len(eq_pairs) + len(neq_pairs)} ä¸ª")
        
        if len(eq_pairs) == 0 and len(neq_pairs) == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰çº¦æŸæ–‡ä»¶çš„ç¨‹åºå¯¹")
            return
        
                 
        results = {
            "eq_results": {
                "success": 0, "failed": 0, "timeout": 0, "exception": 0,
                "equivalent": 0, "suspicious_constraint": 0, "suspicious_output": 0, "not_equivalent": 0,
                "correct_predictions": 0, "wrong_predictions": 0, "total_time": 0,
                "detailed_results": []
            },
            "neq_results": {
                "success": 0, "failed": 0, "timeout": 0, "exception": 0,
                "equivalent": 0, "suspicious_constraint": 0, "suspicious_output": 0, "not_equivalent": 0,
                "correct_predictions": 0, "wrong_predictions": 0, "total_time": 0,
                "detailed_results": []
            }
        }
        
                 
        if eq_pairs:
            print(f"\nğŸŸ¢ åˆ†æEqç¨‹åºå¯¹ (æœŸæœ›ï¼šç­‰ä»·)")
            print("-" * 40)
            
            for i, pair in enumerate(eq_pairs, 1):
                print(f"[{i}/{len(eq_pairs)}] ", end="")
                result = self.run_equivalence_analysis(pair['dir'], "Eq")
                
                results["eq_results"]["total_time"] += result["time"]
                
                        
                detail = {
                    "dir": pair['dir'],
                    "result": result,
                    "expected": "equivalent",
                    "actual": result.get("equivalence_status", "unknown")
                }
                results["eq_results"]["detailed_results"].append(detail)
                
                if result["status"] == "success":
                    results["eq_results"]["success"] += 1
                    
                            
                    eq_status = result.get("equivalence_status", "unknown")
                    if eq_status in results["eq_results"]:
                        results["eq_results"][eq_status] += 1
                    
                             
                    if eq_status == "equivalent":               
                        results["eq_results"]["correct_predictions"] += 1
                    else:                   
                        results["eq_results"]["wrong_predictions"] += 1
                        
                elif result["status"] == "failed":
                    results["eq_results"]["failed"] += 1
                elif result["status"] == "timeout":
                    results["eq_results"]["timeout"] += 1
                else:
                    results["eq_results"]["exception"] += 1
        
                  
        if neq_pairs:
            print(f"\nğŸ”´ åˆ†æNEqç¨‹åºå¯¹ (æœŸæœ›ï¼šä¸ç­‰ä»·)")
            print("-" * 40)
            
            for i, pair in enumerate(neq_pairs, 1):
                print(f"[{i}/{len(neq_pairs)}] ", end="")
                result = self.run_equivalence_analysis(pair['dir'], "NEq")
                
                results["neq_results"]["total_time"] += result["time"]
                
                        
                detail = {
                    "dir": pair['dir'],
                    "result": result,
                    "expected": "not_equivalent",
                    "actual": result.get("equivalence_status", "unknown")
                }
                results["neq_results"]["detailed_results"].append(detail)
                
                if result["status"] == "success":
                    results["neq_results"]["success"] += 1
                    
                            
                    neq_status = result.get("equivalence_status", "unknown")
                    if neq_status in results["neq_results"]:
                        results["neq_results"][neq_status] += 1
                    
                             
                    if neq_status in ["not_equivalent", "suspicious_constraint", "suspicious_output"]:                    
                        results["neq_results"]["correct_predictions"] += 1
                    else:                
                        results["neq_results"]["wrong_predictions"] += 1
                        
                elif result["status"] == "failed":
                    results["neq_results"]["failed"] += 1
                elif result["status"] == "timeout":
                    results["neq_results"]["timeout"] += 1
                else:
                    results["neq_results"]["exception"] += 1
        
                   
        self.generate_enhanced_summary_report(results, eq_pairs, neq_pairs)
        
        return results
    
    def generate_enhanced_summary_report(self, results, eq_pairs, neq_pairs):
        """ç”Ÿæˆå¢å¼ºçš„æ€»ç»“æŠ¥å‘Š"""
        print(f"\n" + "=" * 60)
        print("ğŸ¯ å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†æå®Œæˆç»Ÿè®¡:")
        
                 
        eq_stats = results["eq_results"]
        print(f"\nğŸŸ¢ Eqç¨‹åºå¯¹ (æœŸæœ›ç­‰ä»·ï¼Œå…±{len(eq_pairs)}ä¸ª):")
        print(f"  æˆåŠŸåˆ†æ: {eq_stats['success']}")
        print(f"  åˆ†æå¤±è´¥: {eq_stats['failed']}")
        print(f"  åˆ†æè¶…æ—¶: {eq_stats['timeout']}")
        print(f"  å‘ç”Ÿå¼‚å¸¸: {eq_stats['exception']}")
        if eq_stats['success'] > 0:
            print(f"  ğŸ“Š å››ç±»ç»“æœåˆ†å¸ƒ:")
            print(f"    âœ… ç­‰ä»·: {eq_stats['equivalent']}")
            print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ: {eq_stats['suspicious_constraint']}")
            print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º: {eq_stats['suspicious_output']}")
            print(f"    âŒ ä¸ç­‰ä»·: {eq_stats['not_equivalent']}")
            print(f"  æ­£ç¡®é¢„æµ‹: {eq_stats['correct_predictions']} (å‡†ç¡®ç‡: {eq_stats['correct_predictions']/eq_stats['success']*100:.1f}%)")
            print(f"  é”™è¯¯é¢„æµ‹: {eq_stats['wrong_predictions']}")
        print(f"  æ€»ç”¨æ—¶: {eq_stats['total_time']:.1f}s")
        
                  
        neq_stats = results["neq_results"]
        print(f"\nğŸ”´ NEqç¨‹åºå¯¹ (æœŸæœ›ä¸ç­‰ä»·ï¼Œå…±{len(neq_pairs)}ä¸ª):")
        print(f"  æˆåŠŸåˆ†æ: {neq_stats['success']}")
        print(f"  åˆ†æå¤±è´¥: {neq_stats['failed']}")
        print(f"  åˆ†æè¶…æ—¶: {neq_stats['timeout']}")
        print(f"  å‘ç”Ÿå¼‚å¸¸: {neq_stats['exception']}")
        if neq_stats['success'] > 0:
            print(f"  ğŸ“Š å››ç±»ç»“æœåˆ†å¸ƒ:")
            print(f"    âœ… ç­‰ä»·: {neq_stats['equivalent']}")
            print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ: {neq_stats['suspicious_constraint']}")
            print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º: {neq_stats['suspicious_output']}")
            print(f"    âŒ ä¸ç­‰ä»·: {neq_stats['not_equivalent']}")
            print(f"  æ­£ç¡®é¢„æµ‹: {neq_stats['correct_predictions']} (å‡†ç¡®ç‡: {neq_stats['correct_predictions']/neq_stats['success']*100:.1f}%)")
            print(f"  é”™è¯¯é¢„æµ‹: {neq_stats['wrong_predictions']}")
        print(f"  æ€»ç”¨æ—¶: {neq_stats['total_time']:.1f}s")
        
              
        total_programs = len(eq_pairs) + len(neq_pairs)
        total_success = eq_stats['success'] + neq_stats['success']
        total_correct = eq_stats['correct_predictions'] + neq_stats['correct_predictions']
        total_time = eq_stats['total_time'] + neq_stats['total_time']
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»ç¨‹åºå¯¹: {total_programs}")
        print(f"  æˆåŠŸåˆ†æ: {total_success} (æˆåŠŸç‡: {total_success/total_programs*100:.1f}%)")
        if total_success > 0:
            print(f"  é¢„æµ‹å‡†ç¡®: {total_correct} (å‡†ç¡®ç‡: {total_correct/total_success*100:.1f}%)")
        print(f"  æ€»åˆ†ææ—¶é—´: {total_time:.1f}s")
        print(f"  å¹³å‡åˆ†ææ—¶é—´: {total_time/max(1, total_success):.1f}s")
        
                  
        report_file = "enhanced_batch_equivalence_analysis_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("å››ç±»åˆ¤æ–­æµç¨‹:\n")
            f.write("  1ï¸âƒ£  çº¦æŸç­‰ä»·ä¸”è¾“å‡ºç›¸åŒ â†’ ç­‰ä»·\n")
            f.write("  2ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä½†è¾“å‡ºç›¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆçº¦æŸï¼‰\n")
            f.write("  3ï¸âƒ£  çº¦æŸç­‰ä»·ä½†è¾“å‡ºä¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆè¾“å‡ºï¼‰\n")
            f.write("  4ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä¸”è¾“å‡ºä¸åŒ â†’ ä¸ç­‰ä»·\n\n")
            
            f.write("æ€»ä½“ç»Ÿè®¡:\n")
            f.write(f"  Eqç¨‹åºå¯¹: {len(eq_pairs)} ä¸ª\n")
            f.write(f"  NEqç¨‹åºå¯¹: {len(neq_pairs)} ä¸ª\n")
            f.write(f"  æ€»ç¨‹åºå¯¹: {total_programs} ä¸ª\n")
            f.write(f"  æˆåŠŸåˆ†æ: {total_success} ä¸ª ({total_success/total_programs*100:.1f}%)\n")
            if total_success > 0:
                f.write(f"  é¢„æµ‹å‡†ç¡®: {total_correct} ä¸ª ({total_correct/total_success*100:.1f}%)\n")
            f.write(f"  æ€»åˆ†ææ—¶é—´: {total_time:.1f} ç§’\n\n")
            
                      
            f.write("Eqç¨‹åºå››ç±»ç»“æœè¯¦æƒ…:\n")
            f.write("-" * 30 + "\n")
            for detail in eq_stats['detailed_results']:
                if detail['result']['status'] == 'success':
                    f.write(f"  {os.path.relpath(detail['dir'], self.base_dir)}: {detail['actual']}\n")
            f.write("\n")
            
            f.write("NEqç¨‹åºå››ç±»ç»“æœè¯¦æƒ…:\n")
            f.write("-" * 30 + "\n")
            for detail in neq_stats['detailed_results']:
                if detail['result']['status'] == 'success':
                    f.write(f"  {os.path.relpath(detail['dir'], self.base_dir)}: {detail['actual']}\n")
            f.write("\n")
            
            f.write("è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å„ä¸ªç¨‹åºç›®å½•ä¸‹çš„ equivalence_analysis_*.txt æ–‡ä»¶\n")
        
        print(f"\nğŸ“„ å¢å¼ºçš„æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¯åŠ¨å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†æï¼ˆå…¨éƒ¨benchmarkï¼‰...")
    
    analyzer = EnhancedBatchEquivalenceAnalyzer()
    
            
    results = analyzer.analyze_all_programs()
    
    print(f"\nâœ… å¢å¼ºçš„æ‰¹é‡ç­‰ä»·æ€§åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    main()
