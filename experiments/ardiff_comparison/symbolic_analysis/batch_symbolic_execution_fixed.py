                      
"""
æ‰¹é‡ç¬¦å·æ‰§è¡Œè„šæœ¬ - ä¸“é—¨é’ˆå¯¹ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶
å¯¹æ‰€æœ‰ symbolic_* å¯æ‰§è¡Œæ–‡ä»¶è¿›è¡Œç¬¦å·æ‰§è¡Œï¼Œç”Ÿæˆæœ‰æ„ä¹‰çš„çº¦æŸå…¬å¼
"""

import os
import subprocess
import time
import datetime
import glob
import sys
from pathlib import Path

class SymbolicBatchExecutor:
    """ç¬¦å·åŒ–æ–‡ä»¶æ‰¹é‡æ‰§è¡Œå™¨"""
    
    def __init__(self, benchmark_dir="benchmarks", timeout=60):
        self.benchmark_dir = benchmark_dir
        self.timeout = timeout
        self.results = {}
        self.failed_executions = []
        self.successful_executions = []
        
              
        self.start_time = None
        self.end_time = None
        self.total_files = 0
        self.processed_files = 0
        
    def find_all_symbolic_executables(self):
        """æŸ¥æ‰¾æ‰€æœ‰ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶"""
        print("ğŸ” æ­£åœ¨æŸ¥æ‰¾æ‰€æœ‰ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶...")
        
        executables = []
        
                               
        for root, dirs, files in os.walk(self.benchmark_dir):
            for file in files:
                if file.startswith('symbolic_') and not file.endswith(('.c', '.java', '.txt', '.md', '.py')):
                    file_path = os.path.join(root, file)
                                
                    if os.access(file_path, os.X_OK):
                        executables.append(file_path)
        
        print(f"ğŸ“‚ å‘ç° {len(executables)} ä¸ªç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶")
        return sorted(executables)
    
    def group_executables_by_test(self):
        """æŒ‰æµ‹è¯•ç»„å¯¹ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶è¿›è¡Œåˆ†ç»„"""
        executables = self.find_all_symbolic_executables()
        
        grouped = {}
        for exe in executables:
                          
                                                                     
            path_parts = Path(exe).parts
            if len(path_parts) >= 4:
                                     
                benchmark_idx = path_parts.index('benchmarks')
                test_group = '/'.join(path_parts[benchmark_idx+1:-1])         
                filename = path_parts[-1]                                 
                
                        
                if filename.startswith('symbolic_'):
                    version = filename[9:]                     
                else:
                    version = filename
                
                if test_group not in grouped:
                    grouped[test_group] = {}
                grouped[test_group][version] = exe
        
        return grouped
    
    def run_symbolic_execution_single(self, executable_path):
        """å¯¹å•ä¸ªç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶è¿è¡Œç¬¦å·æ‰§è¡Œ"""
                
        exe_name = os.path.basename(executable_path)
        exe_dir = os.path.dirname(executable_path)
        output_prefix = os.path.join(exe_dir, f"se_{exe_name}")
        
        print(f"  ğŸ”¬ åˆ†æ: {executable_path}")
        print(f"     è¾“å‡ºå‰ç¼€: {output_prefix}")
        
        try:
                      
            cmd = [
                sys.executable, "se_script.py",
                "--binary", executable_path,
                "--timeout", str(self.timeout),
                "--output-prefix", output_prefix
            ]
            
                    
            start_time = time.time()
            
                    
            result = subprocess.run(
                cmd,
                cwd=os.getcwd(),
                capture_output=True,
                text=True,
                timeout=self.timeout + 30            
            )
            
                  
            execution_time = time.time() - start_time
            
            if result.returncode == 0:
                    
                print(f"     âœ… æˆåŠŸ (è€—æ—¶: {execution_time:.2f}s)")
                
                         
                pattern = f"{output_prefix}_path_*.txt"
                generated_files = glob.glob(pattern)
                
                                   
                meaningful_constraints = 0
                for constraint_file in generated_files:
                    if self.check_constraint_quality(constraint_file):
                        meaningful_constraints += 1
                
                self.successful_executions.append({
                    'executable': executable_path,
                    'output_prefix': output_prefix,
                    'execution_time': execution_time,
                    'generated_files': len(generated_files),
                    'meaningful_constraints': meaningful_constraints,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                })
                
                print(f"     ğŸ“„ ç”Ÿæˆçº¦æŸæ–‡ä»¶: {len(generated_files)} ä¸ª")
                print(f"     ğŸ¯ æœ‰æ„ä¹‰çº¦æŸ: {meaningful_constraints} ä¸ª")
                
                return True, len(generated_files), meaningful_constraints, execution_time
            else:
                    
                print(f"     âŒ å¤±è´¥ (è€—æ—¶: {execution_time:.2f}s)")
                print(f"        é”™è¯¯: {result.stderr[:200]}...")
                
                self.failed_executions.append({
                    'executable': executable_path,
                    'execution_time': execution_time,
                    'return_code': result.returncode,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                })
                
                return False, 0, 0, execution_time
                
        except subprocess.TimeoutExpired:
            print(f"     â° è¶…æ—¶ (>{self.timeout}s)")
            self.failed_executions.append({
                'executable': executable_path,
                'execution_time': self.timeout,
                'return_code': -1,
                'error': 'timeout'
            })
            return False, 0, 0, self.timeout
            
        except Exception as e:
            print(f"     ğŸ’¥ å¼‚å¸¸: {str(e)}")
            self.failed_executions.append({
                'executable': executable_path,
                'execution_time': 0,
                'return_code': -2,
                'error': str(e)
            })
            return False, 0, 0, 0
    
    def check_constraint_quality(self, constraint_file):
        """æ£€æŸ¥çº¦æŸæ–‡ä»¶æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„çº¦æŸ"""
        try:
            with open(constraint_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
                          
            indicators = [
                'scanf_' in content,             
                'count: 0' not in content,           
                '(assert' in content,           
                'variables\': {}' not in content,         
            ]
            
                             
            return sum(indicators) >= 2
            
        except Exception as e:
            print(f"æ£€æŸ¥çº¦æŸæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def run_batch_analysis(self):
        """è¿è¡Œæ‰¹é‡åˆ†æ"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ç¬¦å·æ‰§è¡Œåˆ†æ (ç¬¦å·åŒ–ç‰ˆæœ¬)")
        print("=" * 60)
        
        self.start_time = time.time()
        start_datetime = datetime.datetime.now()
        print(f"å¼€å§‹æ—¶é—´: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        
                
        grouped_executables = self.group_executables_by_test()
        self.total_files = sum(len(versions) for versions in grouped_executables.values())
        
        print(f"æµ‹è¯•ç»„æ•°é‡: {len(grouped_executables)}")
        print(f"ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶æ€»æ•°: {self.total_files}")
        print()
        
        total_meaningful_constraints = 0
        
                   
        for test_group, versions in grouped_executables.items():
            print(f"\nğŸ“‹ æµ‹è¯•ç»„: {test_group}")
            print("-" * 40)
            
            test_results = {}
            
            for version, executable_path in versions.items():
                self.processed_files += 1
                progress = (self.processed_files / self.total_files) * 100
                
                print(f"è¿›åº¦: [{self.processed_files}/{self.total_files}] {progress:.1f}%")
                
                success, paths_count, meaningful_count, exec_time = self.run_symbolic_execution_single(executable_path)
                
                test_results[version] = {
                    'success': success,
                    'paths_count': paths_count,
                    'meaningful_constraints': meaningful_count,
                    'execution_time': exec_time,
                    'executable_path': executable_path
                }
                
                total_meaningful_constraints += meaningful_count
            
            self.results[test_group] = test_results
        
        self.end_time = time.time()
        total_time = self.end_time - self.start_time
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰¹é‡ç¬¦å·æ‰§è¡Œå®Œæˆ!")
        print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"å¹³å‡æ¯ä¸ªæ–‡ä»¶: {total_time/self.total_files:.2f} ç§’")
        print(f"æˆåŠŸ: {len(self.successful_executions)}/{self.total_files}")
        print(f"å¤±è´¥: {len(self.failed_executions)}/{self.total_files}")
        print(f"æ€»æœ‰æ„ä¹‰çº¦æŸ: {total_meaningful_constraints} ä¸ª")
        
        return self.results
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        report_file = "symbolic_execution_fixed_report.txt"
        
        total_meaningful_constraints = sum(exe['meaningful_constraints'] 
                                         for exe in self.successful_executions)
        
        with open(report_file, "w", encoding='utf-8') as f:
            f.write("ç¬¦å·åŒ–æ–‡ä»¶æ‰¹é‡ç¬¦å·æ‰§è¡Œåˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
                  
            f.write("åŸºæœ¬ä¿¡æ¯:\n")
            f.write("-" * 30 + "\n")
            f.write(f"åˆ†æç›®å½•: {self.benchmark_dir}\n")
            f.write(f"è¶…æ—¶è®¾ç½®: {self.timeout} ç§’\n")
            f.write(f"æ€»æ–‡ä»¶æ•°: {self.total_files}\n")
            if self.start_time and self.end_time:
                f.write(f"å¼€å§‹æ—¶é—´: {datetime.datetime.fromtimestamp(self.start_time).strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ç»“æŸæ—¶é—´: {datetime.datetime.fromtimestamp(self.end_time).strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»è€—æ—¶: {self.end_time - self.start_time:.2f} ç§’\n\n")
            
                  
            f.write("æ‰§è¡Œç»Ÿè®¡:\n")
            f.write("-" * 30 + "\n")
            f.write(f"æˆåŠŸæ‰§è¡Œ: {len(self.successful_executions)} ä¸ª\n")
            f.write(f"å¤±è´¥æ‰§è¡Œ: {len(self.failed_executions)} ä¸ª\n")
            f.write(f"æˆåŠŸç‡: {len(self.successful_executions)/self.total_files*100:.1f}%\n")
            f.write(f"æ€»æœ‰æ„ä¹‰çº¦æŸ: {total_meaningful_constraints} ä¸ª\n\n")
            
                    
            if self.successful_executions:
                f.write("æˆåŠŸæ¡ˆä¾‹è¯¦æƒ…:\n")
                f.write("-" * 30 + "\n")
                total_paths = 0
                total_time = 0
                
                for exe_info in self.successful_executions:
                    f.write(f"{exe_info['executable']}:\n")
                    f.write(f"  ç”Ÿæˆè·¯å¾„æ•°: {exe_info['generated_files']}\n")
                    f.write(f"  æœ‰æ„ä¹‰çº¦æŸ: {exe_info['meaningful_constraints']}\n")
                    f.write(f"  æ‰§è¡Œæ—¶é—´: {exe_info['execution_time']:.2f} ç§’\n")
                    f.write(f"  è¾“å‡ºå‰ç¼€: {exe_info['output_prefix']}\n\n")
                    
                    total_paths += exe_info['generated_files']
                    total_time += exe_info['execution_time']
                
                f.write(f"æ€»è®¡ç”Ÿæˆè·¯å¾„æ•°: {total_paths}\n")
                f.write(f"å¹³å‡è·¯å¾„æ•°/æ–‡ä»¶: {total_paths/len(self.successful_executions):.1f}\n")
                f.write(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {total_time/len(self.successful_executions):.2f} ç§’\n")
                f.write(f"çº¦æŸè´¨é‡ç‡: {total_meaningful_constraints/total_paths*100:.1f}%\n\n")
            
                     
            f.write("æµ‹è¯•ç»„ç»“æœ:\n")
            f.write("-" * 30 + "\n")
            
            for test_group, versions in self.results.items():
                f.write(f"\n{test_group}:\n")
                for version, result in versions.items():
                    status = "âœ…" if result['success'] else "âŒ"
                    f.write(f"  {version}: {status} ")
                    f.write(f"è·¯å¾„æ•°={result['paths_count']} ")
                    f.write(f"æœ‰æ•ˆçº¦æŸ={result['meaningful_constraints']} ")
                    f.write(f"æ—¶é—´={result['execution_time']:.2f}s\n")
            
            f.write("\nç”Ÿæˆçš„çº¦æŸæ–‡ä»¶:\n")
            f.write("-" * 30 + "\n")
            f.write("æ¯ä¸ªæˆåŠŸåˆ†æçš„ç¬¦å·åŒ–æ–‡ä»¶éƒ½ç”Ÿæˆäº†ä»¥ä¸‹æ–‡ä»¶:\n")
            f.write("- se_symbolic_{exe_name}_path_*.txt  - è·¯å¾„çº¦æŸæ–‡ä»¶\n")
            f.write("- se_symbolic_{exe_name}_timing_report.txt  - æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("\næŸ¥çœ‹æœ‰æ„ä¹‰çº¦æŸæ–‡ä»¶ç¤ºä¾‹:\n")
            f.write("find . -name 'se_symbolic_*_path_*.txt' | head -5\n")
            
        print(f"ğŸ“„ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    def get_statistics(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.start_time or not self.end_time:
            return None
            
        total_paths = sum(exe['generated_files'] for exe in self.successful_executions)
        total_meaningful = sum(exe['meaningful_constraints'] for exe in self.successful_executions)
        
        return {
            'total_files': self.total_files,
            'successful': len(self.successful_executions),
            'failed': len(self.failed_executions),
            'success_rate': len(self.successful_executions) / self.total_files * 100,
            'total_time': self.end_time - self.start_time,
            'avg_time_per_file': (self.end_time - self.start_time) / self.total_files,
            'total_paths_generated': total_paths,
            'total_meaningful_constraints': total_meaningful,
            'constraint_quality_rate': total_meaningful / total_paths * 100 if total_paths > 0 else 0,
            'avg_paths_per_file': total_paths / max(1, len(self.successful_executions))
        }

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¬¦å·åŒ–æ–‡ä»¶æ‰¹é‡ç¬¦å·æ‰§è¡Œåˆ†æå·¥å…·')
    parser.add_argument('--benchmark-dir', default='benchmarks', help='benchmarkç›®å½•è·¯å¾„')
    parser.add_argument('--timeout', type=int, default=60, help='å•ä¸ªæ–‡ä»¶çš„è¶…æ—¶æ—¶é—´(ç§’)')
    
    args = parser.parse_args()
    
          
    if not os.path.exists('se_script.py'):
        print("âŒ æ‰¾ä¸åˆ° se_script.pyï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨")
        return 1
    
    if not os.path.exists(args.benchmark_dir):
        print(f"âŒ æ‰¾ä¸åˆ°benchmarkç›®å½•: {args.benchmark_dir}")
        return 1
    
             
    executor = SymbolicBatchExecutor(
        benchmark_dir=args.benchmark_dir,
        timeout=args.timeout
    )
    
    try:
                
        results = executor.run_batch_analysis()
        
              
        executor.generate_comprehensive_report()
        
                
        stats = executor.get_statistics()
        if stats:
            print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
            print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
            print(f"  æ€»è·¯å¾„æ•°: {stats['total_paths_generated']}")
            print(f"  æœ‰æ„ä¹‰çº¦æŸæ•°: {stats['total_meaningful_constraints']}")
            print(f"  çº¦æŸè´¨é‡ç‡: {stats['constraint_quality_rate']:.1f}%")
            print(f"  å¹³å‡è·¯å¾„æ•°: {stats['avg_paths_per_file']:.1f}")
            print(f"  æ€»è€—æ—¶: {stats['total_time']:.2f} ç§’")
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâ›” ç”¨æˆ·ä¸­æ–­äº†æ‰¹é‡åˆ†æ")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ æ‰¹é‡åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 