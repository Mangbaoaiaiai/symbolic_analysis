                      
"""
çº¦æŸç”Ÿæˆé—®é¢˜ä¿®å¤åˆ†ææŠ¥å‘Š
"""

import os
import glob
import time
from pathlib import Path

def analyze_constraint_generation():
    """åˆ†æçº¦æŸç”Ÿæˆä¿®å¤æˆæœ"""
    
    print("ğŸ” çº¦æŸç”Ÿæˆé—®é¢˜ä¿®å¤åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
               
    executables = []
    for file_path in glob.glob("/root/ardiff/symbolic_analysis/benchmarks/**/symbolic_*", recursive=True):
        if os.path.isfile(file_path) and os.access(file_path, os.X_OK) and not file_path.endswith('.c'):
            executables.append(file_path)
    
    print(f"ğŸ“Š æ€»ç¬¦å·åŒ–å¯æ‰§è¡Œæ–‡ä»¶æ•°: {len(executables)}")
    
            
    constraint_files = glob.glob("/root/ardiff/symbolic_analysis/benchmarks/**/*_path_*.txt", recursive=True)
    print(f"ğŸ“„ æ€»çº¦æŸæ–‡ä»¶æ•°: {len(constraint_files)}")
    
                
    meaningful_constraints = 0
    for constraint_file in constraint_files:
        try:
            with open(constraint_file, 'r', encoding='utf-8') as f:
                content = f.read()
            if '(assert' in content and ('mem_' in content or 'scanf_' in content):
                meaningful_constraints += 1
        except:
            continue
    
    print(f"âœ… æœ‰æ„ä¹‰çº¦æŸæ–‡ä»¶æ•°: {meaningful_constraints}")
    print(f"ğŸ“ˆ çº¦æŸè´¨é‡ç‡: {(meaningful_constraints/max(1, len(constraint_files)))*100:.1f}%")
    
             
    test_cases = {}
    for constraint_file in constraint_files:
                  
        parts = Path(constraint_file).parts
        if 'benchmarks' in parts:
            idx = parts.index('benchmarks')
            if len(parts) > idx + 3:
                test_case = '/'.join(parts[idx+1:idx+4])                   
                if test_case not in test_cases:
                    test_cases[test_case] = {'total': 0, 'meaningful': 0}
                test_cases[test_case]['total'] += 1
                
                         
                try:
                    with open(constraint_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    if '(assert' in content and ('mem_' in content or 'scanf_' in content):
                        test_cases[test_case]['meaningful'] += 1
                except:
                    pass
    
    print(f"\nğŸ“‹ æŒ‰æµ‹è¯•ç”¨ä¾‹ç»Ÿè®¡ (å…± {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹):")
    print("-" * 50)
    
    successful_test_cases = []
    for test_case, stats in sorted(test_cases.items()):
        quality_rate = (stats['meaningful'] / max(1, stats['total'])) * 100
        status = "âœ…" if quality_rate == 100 else "âš ï¸" if quality_rate > 0 else "âŒ"
        print(f"{status} {test_case}: {stats['meaningful']}/{stats['total']} ({quality_rate:.0f}%)")
        if stats['meaningful'] > 0:
            successful_test_cases.append(test_case)
    
    print(f"\nğŸ¯ æˆåŠŸç”Ÿæˆçº¦æŸçš„æµ‹è¯•ç”¨ä¾‹æ•°: {len(successful_test_cases)}")
    
            
    print(f"\nğŸ› ï¸ é—®é¢˜ä¿®å¤æ€»ç»“:")
    print("=" * 40)
    
    print("ğŸ” å‘ç°çš„é—®é¢˜:")
    print("  1. se_script.py åœ¨å½“å‰å·¥ä½œç›®å½•ä¿å­˜çº¦æŸæ–‡ä»¶")
    print("  2. batch_generate_all_constraints.py åœ¨å¯æ‰§è¡Œæ–‡ä»¶ç›®å½•æŸ¥æ‰¾çº¦æŸæ–‡ä»¶")
    print("  3. æ–‡ä»¶ä¿å­˜ä½ç½®ä¸åŒ¹é…å¯¼è‡´æ‰¹é‡è„šæœ¬æ‰¾ä¸åˆ°çº¦æŸæ–‡ä»¶")
    print("  4. å› æ­¤ä¹‹å‰æŠ¥å‘Šæ‰€æœ‰çº¦æŸæ–‡ä»¶ä¸ºç©º")
    
    print("\nâœ… ä¿®å¤æªæ–½:")
    print("  1. ä¿®æ”¹ se_script.py ä¸­ save_path_to_file() æ–¹æ³•")
    print("  2. å°†çº¦æŸæ–‡ä»¶ä¿å­˜åˆ°å¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ç›®å½•")
    print("  3. ä¿®æ”¹ generate_timing_report() æ–¹æ³•")
    print("  4. å°†æ—¶é—´æŠ¥å‘Šä¹Ÿä¿å­˜åˆ°å¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ç›®å½•")
    
    print("\nğŸ‰ ä¿®å¤æ•ˆæœ:")
    print(f"  â€¢ ä¿®å¤å‰: åªæœ‰ 2 ä¸ªæœ‰æ„ä¹‰çº¦æŸæ–‡ä»¶")
    print(f"  â€¢ ä¿®å¤å: {meaningful_constraints} ä¸ªæœ‰æ„ä¹‰çº¦æŸæ–‡ä»¶")
    print(f"  â€¢ æ”¹å–„å€æ•°: {meaningful_constraints/2:.0f}x")
    print(f"  â€¢ è¦†ç›–æµ‹è¯•ç”¨ä¾‹: {len(successful_test_cases)} ä¸ª")
    
            
    constraint_types = {
        'bvsge': 0, 'bvslt': 0, 'bvuge': 0, 'bvule': 0, 
        'bvsgt': 0, 'bvugt': 0, 'eq': 0, 'other': 0
    }
    
    for constraint_file in constraint_files:
        try:
            with open(constraint_file, 'r', encoding='utf-8') as f:
                content = f.read()
            for ctype in constraint_types:
                if ctype in content:
                    constraint_types[ctype] += content.count(ctype)
        except:
            continue
    
    print(f"\nğŸ“Š çº¦æŸç±»å‹åˆ†æ:")
    print("-" * 30)
    for ctype, count in sorted(constraint_types.items()):
        if count > 0:
            print(f"  {ctype}: {count} æ¬¡")
    
            
    print(f"\nğŸ’¡ çº¦æŸç¤ºä¾‹:")
    print("-" * 20)
    if constraint_files:
        example_file = constraint_files[0]
        try:
            with open(example_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            print(f"æ–‡ä»¶: {os.path.relpath(example_file, '/root/ardiff/symbolic_analysis')}")
            for i, line in enumerate(lines[:10]):
                if line.strip().startswith('(') or line.strip().startswith(';'):
                    print(f"  {line.rstrip()}")
        except:
            pass
    
    print(f"\nâ° åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ¯ çº¦æŸç”Ÿæˆé—®é¢˜å·²æˆåŠŸä¿®å¤ï¼")

if __name__ == "__main__":
    analyze_constraint_generation() 