                      
"""
çº¦æŸè´¨é‡æ£€æŸ¥è„šæœ¬ - åˆ†ææ‰€æœ‰ç”Ÿæˆçš„çº¦æŸæ–‡ä»¶çš„è´¨é‡
ä¸“é—¨æ£€æŸ¥symbolic_*_path_*.txtæ–‡ä»¶ä¸­çš„æœ‰æ„ä¹‰çº¦æŸ
"""

import os
import glob
import re
from pathlib import Path

class ConstraintQualityChecker:
    def __init__(self, base_dir="/root/ardiff/symbolic_analysis"):
        self.base_dir = Path(base_dir)
        self.meaningful_constraints = []
        self.empty_constraints = []
        self.constraint_summary = {}
        
    def analyze_constraint_file(self, file_path):
        """åˆ†æå•ä¸ªçº¦æŸæ–‡ä»¶çš„è´¨é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
                          
            indicators = {
                'has_scanf_vars': 'scanf_' in content,
                'has_smt_assertions': '(assert' in content and content.count('(assert') > 0,
                'non_zero_constraints': 'count: 0' not in content,
                'has_variables': "variables': {}" not in content and "è¾“å…¥å˜é‡å€¼: {}" not in content,
                'has_bitvec_declarations': 'declare-fun' in content and 'BitVec' in content,
                'has_program_output': 'Result:' in content and content.split('Result:')[1].strip() != ''
            }
            
                    
            constraint_count_match = re.search(r"count[':]\s*(\d+)", content)
            constraint_count = int(constraint_count_match.group(1)) if constraint_count_match else 0
            
                    
            var_match = re.search(r"è¾“å…¥å˜é‡å€¼:\s*({[^}]*})", content)
            variables_info = var_match.group(1) if var_match else "{}"
            
                    
            output_match = re.search(r"Result:\s*([^\n]+)", content)
            program_output = output_match.group(1).strip() if output_match else ""
            
                    
            quality_score = sum(indicators.values())
            is_meaningful = quality_score >= 3            
            
            file_info = {
                'file_path': str(file_path),
                'quality_score': quality_score,
                'is_meaningful': is_meaningful,
                'constraint_count': constraint_count,
                'variables_info': variables_info,
                'program_output': program_output,
                'indicators': indicators,
                'content_preview': content[:200] + "..." if len(content) > 200 else content
            }
            
            if is_meaningful:
                self.meaningful_constraints.append(file_info)
            else:
                self.empty_constraints.append(file_info)
                
            return file_info
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            return None
    
    def find_all_constraint_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰çº¦æŸæ–‡ä»¶"""
                    
        pattern = str(self.base_dir / "**" / "*_path_*.txt")
        constraint_files = glob.glob(pattern, recursive=True)
        return sorted(constraint_files)
    
    def analyze_all_constraints(self):
        """åˆ†ææ‰€æœ‰çº¦æŸæ–‡ä»¶"""
        print("ğŸ” å¼€å§‹åˆ†ææ‰€æœ‰çº¦æŸæ–‡ä»¶...")
        
        constraint_files = self.find_all_constraint_files()
        print(f"ğŸ“‹ æ‰¾åˆ° {len(constraint_files)} ä¸ªçº¦æŸæ–‡ä»¶")
        
               
        symbolic_files = [f for f in constraint_files if 'symbolic_' in os.path.basename(f)]
        original_files = [f for f in constraint_files if 'symbolic_' not in os.path.basename(f)]
        
        print(f"  â€¢ ç¬¦å·åŒ–ç‰ˆæœ¬æ–‡ä»¶: {len(symbolic_files)}ä¸ª")
        print(f"  â€¢ åŸå§‹ç‰ˆæœ¬æ–‡ä»¶: {len(original_files)}ä¸ª\n")
        
                
        for i, file_path in enumerate(constraint_files, 1):
            print(f"[{i}/{len(constraint_files)}] åˆ†æ: {os.path.relpath(file_path, self.base_dir)}")
            self.analyze_constraint_file(file_path)
            
        return len(constraint_files)
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„çº¦æŸè´¨é‡æŠ¥å‘Š"""
        total_files = len(self.meaningful_constraints) + len(self.empty_constraints)
        
        if total_files == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°çº¦æŸæ–‡ä»¶è¿›è¡Œåˆ†æ")
            return
        
        meaningful_count = len(self.meaningful_constraints)
        empty_count = len(self.empty_constraints)
        meaningful_rate = (meaningful_count / total_files) * 100
        
        report = f"""
ğŸ¯ çº¦æŸè´¨é‡åˆ†æè¯¦ç»†æŠ¥å‘Š
{'='*60}

ğŸ“Š æ€»ä½“ç»Ÿè®¡:
  â€¢ æ€»çº¦æŸæ–‡ä»¶æ•°: {total_files}
  â€¢ æœ‰æ„ä¹‰çº¦æŸæ•°: {meaningful_count}
  â€¢ ç©ºçº¦æŸæ•°: {empty_count}
  â€¢ æœ‰æ„ä¹‰æ¯”ç‡: {meaningful_rate:.1f}%

ğŸ† é«˜è´¨é‡çº¦æŸæ–‡ä»¶è¯¦æƒ…:
{'='*40}
"""
        
        if self.meaningful_constraints:
            for i, constraint in enumerate(self.meaningful_constraints, 1):
                file_name = os.path.relpath(constraint['file_path'], self.base_dir)
                report += f"""
[{i}] {file_name}
  âœ… è´¨é‡åˆ†æ•°: {constraint['quality_score']}/6
  ğŸ“Š çº¦æŸæ•°é‡: {constraint['constraint_count']}
  ğŸ² è¾“å…¥å˜é‡: {constraint['variables_info']}
  ğŸ“¤ ç¨‹åºè¾“å‡º: {constraint['program_output']}
  ğŸ” è´¨é‡æŒ‡æ ‡:
"""
                for indicator, value in constraint['indicators'].items():
                    status = "âœ…" if value else "âŒ"
                    report += f"    {status} {indicator}: {value}\n"
        else:
            report += "  âŒ æš‚æ— é«˜è´¨é‡çº¦æŸæ–‡ä»¶\n"
        
        report += f"""
ğŸ“ ç©ºçº¦æŸæ–‡ä»¶æ¦‚è§ˆ:
{'='*40}
"""
        
        if self.empty_constraints:
                          
            empty_by_test = {}
            for constraint in self.empty_constraints:
                test_name = self.extract_test_name(constraint['file_path'])
                if test_name not in empty_by_test:
                    empty_by_test[test_name] = []
                empty_by_test[test_name].append(constraint)
            
            for test_name, constraints in empty_by_test.items():
                report += f"\nğŸ”¸ {test_name}: {len(constraints)}ä¸ªç©ºçº¦æŸæ–‡ä»¶\n"
                for constraint in constraints[:2]:            
                    file_name = os.path.basename(constraint['file_path'])
                    report += f"    â€¢ {file_name} (è´¨é‡åˆ†æ•°: {constraint['quality_score']}/6)\n"
                if len(constraints) > 2:
                    report += f"    â€¢ ... è¿˜æœ‰{len(constraints)-2}ä¸ªæ–‡ä»¶\n"
        else:
            report += "  ğŸ‰ æ²¡æœ‰ç©ºçº¦æŸæ–‡ä»¶!\n"
        
        report += f"""
ğŸ¯ ç¬¦å·åŒ–ç¨‹åºä¸“é¡¹åˆ†æ:
{'='*40}
"""
        
                      
        symbolic_meaningful = [c for c in self.meaningful_constraints if 'symbolic_' in os.path.basename(c['file_path'])]
        symbolic_empty = [c for c in self.empty_constraints if 'symbolic_' in os.path.basename(c['file_path'])]
        symbolic_total = len(symbolic_meaningful) + len(symbolic_empty)
        
        if symbolic_total > 0:
            symbolic_rate = (len(symbolic_meaningful) / symbolic_total) * 100
            report += f"""
  ğŸ“Š ç¬¦å·åŒ–ç¨‹åºçº¦æŸç»Ÿè®¡:
    â€¢ æ€»ç¬¦å·åŒ–çº¦æŸ: {symbolic_total}ä¸ª
    â€¢ æœ‰æ„ä¹‰çº¦æŸ: {len(symbolic_meaningful)}ä¸ª
    â€¢ ç©ºçº¦æŸ: {len(symbolic_empty)}ä¸ª
    â€¢ æˆåŠŸç‡: {symbolic_rate:.1f}%
"""
            
            if symbolic_meaningful:
                report += f"\n  ğŸ† æˆåŠŸçš„ç¬¦å·åŒ–æµ‹è¯•ç”¨ä¾‹:\n"
                for constraint in symbolic_meaningful:
                    test_name = self.extract_test_name(constraint['file_path'])
                    file_name = os.path.basename(constraint['file_path'])
                    report += f"    âœ… {test_name}/{file_name}\n"
        else:
            report += "  âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦å·åŒ–ç¨‹åºçš„çº¦æŸæ–‡ä»¶\n"
        
        report += f"""
ğŸ’¡ æ”¹è¿›å»ºè®®:
{'='*40}
"""
        
        if meaningful_rate < 50:
            report += """
  ğŸ”§ å½“å‰çº¦æŸç”ŸæˆæˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®ï¼š
    1. æ£€æŸ¥ç¨‹åºçš„è¾“å…¥å¤„ç†é€»è¾‘
    2. ä¼˜åŒ–scanfç¬¦å·åŒ–hook
    3. è°ƒæ•´ç¬¦å·æ‰§è¡Œè¶…æ—¶å’Œè·¯å¾„é™åˆ¶
    4. æ”¹è¿›Cç¨‹åºçš„æµ®ç‚¹æ•°å¤„ç†
"""
        else:
            report += """
  ğŸ‰ çº¦æŸç”ŸæˆæˆåŠŸç‡è‰¯å¥½ï¼å¯ä»¥è€ƒè™‘ï¼š
    1. æ‰©å¤§ç¬¦å·å˜é‡çš„å–å€¼èŒƒå›´
    2. å¢åŠ æ›´å¤šè·¯å¾„æ¢ç´¢
    3. ä¼˜åŒ–çº¦æŸæ±‚è§£å™¨é…ç½®
"""
        
        report += f"\nâ±ï¸  åˆ†æå®Œæˆæ—¶é—´: {__import__('time').strftime('%Y-%m-%d %H:%M:%S')}"
        
              
        report_file = self.base_dir / "constraint_quality_analysis_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(report)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        
        return report
    
    def extract_test_name(self, file_path):
        """ä»æ–‡ä»¶è·¯å¾„æå–æµ‹è¯•åç§°"""
        path_parts = Path(file_path).parts
        if 'benchmarks' in path_parts:
            idx = path_parts.index('benchmarks')
            if len(path_parts) > idx + 3:
                return '/'.join(path_parts[idx+1:idx+4])                   
        return os.path.dirname(file_path)
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„çº¦æŸè´¨é‡åˆ†æ"""
        print("ğŸš€ å¯åŠ¨çº¦æŸè´¨é‡åˆ†æ...")
        
        total_analyzed = self.analyze_all_constraints()
        
        if total_analyzed > 0:
            print("\n" + "="*60)
            print("ğŸ‰ çº¦æŸè´¨é‡åˆ†æå®Œæˆï¼")
            self.generate_detailed_report()
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°çº¦æŸæ–‡ä»¶è¿›è¡Œåˆ†æ")
        
        return total_analyzed > 0

if __name__ == "__main__":
    checker = ConstraintQualityChecker()
    checker.run_analysis() 