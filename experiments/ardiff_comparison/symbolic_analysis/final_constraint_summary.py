                      
"""
æœ€ç»ˆçº¦æŸæ€»ç»“è„šæœ¬ - æ€»ç»“æ‰€æœ‰æœ‰æ•ˆçš„çº¦æŸç”Ÿæˆç»“æœ
"""

import os
import glob
import re
from pathlib import Path

def analyze_all_constraints():
    """åˆ†ææ‰€æœ‰çº¦æŸæ–‡ä»¶"""
    print("ğŸ” æ­£åœ¨æ‰«ææ‰€æœ‰çº¦æŸæ–‡ä»¶...")
    
                
    pattern = "/root/ardiff/symbolic_analysis/**/*_path_*.txt"
    constraint_files = glob.glob(pattern, recursive=True)
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(constraint_files)} ä¸ªçº¦æŸæ–‡ä»¶")
    
    meaningful_files = []
    empty_files = []
    
    for file_path in constraint_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
                     
            has_constraints = '(assert' in content
            has_variables = 'scanf_' in content or 'mem_' in content
            has_output = 'Result:' in content and len(content.split('Result:')[1].strip()) > 0
            
            file_info = {
                'path': file_path,
                'has_constraints': has_constraints,
                'has_variables': has_variables,
                'has_output': has_output,
                'size': len(content)
            }
            
            if has_constraints and has_variables:
                meaningful_files.append(file_info)
            else:
                empty_files.append(file_info)
                
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
    
    print(f"\nğŸ“Š åˆ†æç»“æœ:")
    print(f"  â€¢ æœ‰æ„ä¹‰çº¦æŸæ–‡ä»¶: {len(meaningful_files)}")
    print(f"  â€¢ ç©ºçº¦æŸæ–‡ä»¶: {len(empty_files)}")
    
    if meaningful_files:
        print(f"\nğŸ† æœ‰æ„ä¹‰çš„çº¦æŸæ–‡ä»¶:")
        for i, file_info in enumerate(meaningful_files, 1):
            relative_path = os.path.relpath(file_info['path'], '/root/ardiff/symbolic_analysis')
            print(f"  {i}. {relative_path}")
            print(f"     çº¦æŸ: {'âœ…' if file_info['has_constraints'] else 'âŒ'}")
            print(f"     å˜é‡: {'âœ…' if file_info['has_variables'] else 'âŒ'}")
            print(f"     è¾“å‡º: {'âœ…' if file_info['has_output'] else 'âŒ'}")
    
             
    print(f"\nğŸ“ æŒ‰æµ‹è¯•ç”¨ä¾‹åˆ†ç»„:")
    test_groups = {}
    for file_info in meaningful_files:
        path_parts = Path(file_info['path']).parts
        if 'benchmarks' in path_parts:
            idx = path_parts.index('benchmarks')
            if len(path_parts) > idx + 3:
                test_name = '/'.join(path_parts[idx+1:idx+4])
                if test_name not in test_groups:
                    test_groups[test_name] = []
                test_groups[test_name].append(file_info)
    
    for test_name, files in test_groups.items():
        print(f"  ğŸ”¸ {test_name}: {len(files)}ä¸ªçº¦æŸæ–‡ä»¶")
    
    return meaningful_files, empty_files

def generate_usage_guide(meaningful_files):
    """ç”Ÿæˆä½¿ç”¨æŒ‡å—"""
    print(f"\nğŸ“‹ ä½¿ç”¨æŒ‡å—:")
    print(f"{'='*50}")
    
    if meaningful_files:
        print(f"âœ… æ‚¨ç°åœ¨æ‹¥æœ‰ {len(meaningful_files)} ä¸ªæœ‰æ•ˆçš„SMTçº¦æŸæ–‡ä»¶ï¼")
        print(f"\nğŸ” æŸ¥çœ‹çº¦æŸæ–‡ä»¶:")
        print(f"   find . -name '*_path_*.txt' -exec grep -l '(assert' {{}} \\;")
        
        print(f"\nğŸ“„ æŸ¥çœ‹ç‰¹å®šçº¦æŸå†…å®¹:")
        sample_file = os.path.relpath(meaningful_files[0]['path'], '/root/ardiff/symbolic_analysis')
        print(f"   cat {sample_file}")
        
        print(f"\nğŸ§® ä½¿ç”¨Z3æ±‚è§£å™¨æ±‚è§£çº¦æŸ:")
        print(f"   # å®‰è£…Z3")
        print(f"   pip install z3-solver")
        print(f"   # æ±‚è§£çº¦æŸæ–‡ä»¶")
        print(f"   z3 {sample_file}")
        
        print(f"\nğŸ“Š ç»Ÿè®¡çº¦æŸç±»å‹:")
        print(f"   grep -h '(assert' */*/symbolic_*_path_*.txt | sort | uniq -c")
        
    else:
        print(f"âŒ å½“å‰æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçº¦æŸã€‚")
        print(f"\nğŸ”§ å»ºè®®:")
        print(f"   1. æ£€æŸ¥ç¨‹åºæ˜¯å¦æœ‰åˆ†æ”¯é€»è¾‘")
        print(f"   2. ç¡®è®¤scanfè¾“å…¥è¢«æ­£ç¡®ç¬¦å·åŒ–")
        print(f"   3. éªŒè¯ç¨‹åºèƒ½æ­£å¸¸ç¼–è¯‘å’Œè¿è¡Œ")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨æœ€ç»ˆçº¦æŸæ€»ç»“åˆ†æ...")
    meaningful_files, empty_files = analyze_all_constraints()
    generate_usage_guide(meaningful_files)
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼") 