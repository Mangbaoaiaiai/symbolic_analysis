                      
"""
ç”Ÿæˆå®Œæ•´çš„benchmarkæ—¶é—´ç»Ÿè®¡æŠ¥å‘Š
æ”¶é›†ç¬¦å·æ‰§è¡Œå’Œç­‰ä»·æ€§åˆ†æçš„æ—¶é—´æ•°æ®
"""

import os
import glob
import re
from pathlib import Path

class TimingReportGenerator:
    def __init__(self, base_dir="/root/ardiff/symbolic_analysis"):
        self.base_dir = Path(base_dir)
        
    def extract_se_timing(self, program_dir):
        """ä»timingæŠ¥å‘Šä¸­æå–ç¬¦å·æ‰§è¡Œæ—¶é—´"""
        timing_files = glob.glob(os.path.join(program_dir, "*_timing_report.txt"))
        
        total_se_time = 0.0
        total_paths = 0
        
        for timing_file in timing_files:
            try:
                with open(timing_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                        
                time_match = re.search(r'æ€»è®¡æ—¶é—´:\s*([\d.]+)\s*ç§’', content)
                if time_match:
                    total_se_time += float(time_match.group(1))
                
                       
                paths_match = re.search(r'å‘ç°è·¯å¾„æ•°:\s*(\d+)', content)
                if paths_match:
                    total_paths += int(paths_match.group(1))
                    
            except Exception as e:
                print(f"Error reading {timing_file}: {e}")
                
        return total_se_time, total_paths
    
    def extract_eq_timing(self, program_dir, eq_type):
        """ä»ç­‰ä»·æ€§åˆ†ææŠ¥å‘Šä¸­æå–æ—¶é—´"""
        eq_file = os.path.join(program_dir, f"equivalence_analysis_{eq_type}.txt")
        
        if not os.path.exists(eq_file):
            return 0.0, 0, False, "no_file"
            
        try:
            with open(eq_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
                     
            time_match = re.search(r'æ€»åˆ†ææ—¶é—´:\s*([\d.]+)\s*ç§’', content)
            eq_time = float(time_match.group(1)) if time_match else 0.0
            
                     
            result_match = re.search(r'ç¨‹åºç­‰ä»·æ€§:\s*(.*)', content)
            is_equivalent = False
            result_status = "unknown"
            
            if result_match:
                result_text = result_match.group(1).strip()
                if "âœ… ç­‰ä»·" in result_text:
                    is_equivalent = True
                    result_status = "equivalent"
                elif "âŒ ä¸ç­‰ä»·" in result_text:
                    is_equivalent = False
                    result_status = "not_equivalent"
            
                                
            equivalent_pairs = 0
            partial_pairs = 0
            non_equivalent_pairs = 0
            
            eq_match = re.search(r'å®Œå…¨ç­‰ä»·è·¯å¾„å¯¹:\s*(\d+)', content)
            if eq_match:
                equivalent_pairs = int(eq_match.group(1))
                
            partial_match = re.search(r'éƒ¨åˆ†ç­‰ä»·è·¯å¾„å¯¹:\s*(\d+)', content)
            if partial_match:
                partial_pairs = int(partial_match.group(1))
                
            non_eq_match = re.search(r'éç­‰ä»·è·¯å¾„å¯¹:\s*(\d+)', content)
            if non_eq_match:
                non_equivalent_pairs = int(non_eq_match.group(1))
            
            total_comparisons = equivalent_pairs + partial_pairs + non_equivalent_pairs
            
            return eq_time, total_comparisons, is_equivalent, result_status
            
        except Exception as e:
            print(f"Error reading {eq_file}: {e}")
            return 0.0, 0, False, "error"
    
    def get_program_category(self, program_dir):
        """è·å–ç¨‹åºç±»åˆ«"""
        path_parts = Path(program_dir).parts
        if len(path_parts) >= 3:
            return path_parts[1]                           
        return "Unknown"
    
    def collect_all_timing_data(self):
        """æ”¶é›†æ‰€æœ‰ç¨‹åºçš„æ—¶é—´æ•°æ®"""
                     
        eq_reports = glob.glob(str(self.base_dir / "benchmarks" / "**" / "equivalence_analysis_*.txt"), recursive=True)
        
        data = []
        
        for report_file in eq_reports:
            program_dir = os.path.dirname(report_file)
            report_name = os.path.basename(report_file)
            
                             
            if "equivalence_analysis_Eq.txt" in report_name:
                eq_type = "Eq"
            elif "equivalence_analysis_NEq.txt" in report_name:
                eq_type = "NEq"
            else:
                continue
            
                    
            rel_path = os.path.relpath(program_dir, self.base_dir)
            category = self.get_program_category(program_dir)
            
                      
            se_time, se_paths = self.extract_se_timing(program_dir)
            
                       
            eq_time, eq_comparisons, is_equivalent, result_status = self.extract_eq_timing(program_dir, eq_type)
            
                                  
            expected_equivalent = (eq_type == "Eq")
            is_correct = (is_equivalent == expected_equivalent)
            
            data.append({
                'path': rel_path,
                'category': category,
                'type': eq_type,
                'se_time': se_time,
                'se_paths': se_paths,
                'eq_time': eq_time,
                'eq_comparisons': eq_comparisons,
                'total_time': se_time + eq_time,
                'is_equivalent': is_equivalent,
                'result_status': result_status,
                'expected_equivalent': expected_equivalent,
                'is_correct': is_correct
            })
        
        return sorted(data, key=lambda x: (x['category'], x['path'], x['type']))
    
    def generate_markdown_report(self, data, output_file="benchmark_timing_report.md"):
        """ç”ŸæˆMarkdownæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        
                
        total_se_time = sum(d['se_time'] for d in data)
        total_eq_time = sum(d['eq_time'] for d in data)
        total_time = total_se_time + total_eq_time
        total_paths = sum(d['se_paths'] for d in data)
        total_comparisons = sum(d['eq_comparisons'] for d in data)
        
               
        eq_data = [d for d in data if d['type'] == 'Eq']
        neq_data = [d for d in data if d['type'] == 'NEq']
        
        eq_correct = sum(1 for d in eq_data if d['is_correct'])
        neq_correct = sum(1 for d in neq_data if d['is_correct'])
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# BenchmarkéªŒè¯è¿‡ç¨‹å®Œæ•´æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š\n\n")
            
                  
            f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
            f.write("| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |\n")
            f.write("|------|------|------|\n")
            f.write(f"| **ç¬¦å·æ‰§è¡Œæ€»æ—¶é—´** | **{total_se_time:.1f}ç§’** ({total_se_time/60:.1f}åˆ†é’Ÿ) | å æ€»æ—¶é—´{total_se_time/total_time*100:.1f}% |\n")
            f.write(f"| **ç­‰ä»·æ€§åˆ†ææ€»æ—¶é—´** | **{total_eq_time:.1f}ç§’** | å æ€»æ—¶é—´{total_eq_time/total_time*100:.1f}% |\n")
            f.write(f"| **æ€»éªŒè¯æ—¶é—´** | **{total_time:.1f}ç§’** ({total_time/60:.1f}åˆ†é’Ÿ) | å®Œæ•´éªŒè¯æµç¨‹ |\n")
            f.write(f"| **åˆ†æç¨‹åºå¯¹æ•°** | **{len(data)}ä¸ª** | {len(eq_data)}ä¸ªEq + {len(neq_data)}ä¸ªNEq |\n")
            f.write(f"| **æ€»è·¯å¾„æ•°** | **{total_paths}æ¡** | ç¬¦å·æ‰§è¡Œç”Ÿæˆ |\n")
            f.write(f"| **æ€»æ¯”è¾ƒæ¬¡æ•°** | **{total_comparisons}æ¬¡** | è·¯å¾„å¯¹æ¯”è¾ƒ |\n")
            f.write(f"| **é¢„æµ‹å‡†ç¡®ç‡** | **{(eq_correct+neq_correct)/len(data)*100:.1f}%** | {eq_correct+neq_correct}/{len(data)}æ­£ç¡® |\n")
            f.write("\n")
            
                   
            f.write("## åˆ†ç±»ç»Ÿè®¡\n\n")
            f.write("| ç±»å‹ | ç¨‹åºæ•° | ç¬¦å·æ‰§è¡Œæ—¶é—´ | ç­‰ä»·æ€§åˆ†ææ—¶é—´ | æ­£ç¡®é¢„æµ‹ | å‡†ç¡®ç‡ |\n")
            f.write("|------|--------|--------------|----------------|----------|--------|\n")
            
            eq_se_time = sum(d['se_time'] for d in eq_data)
            eq_eq_time = sum(d['eq_time'] for d in eq_data)
            f.write(f"| **Eq (åº”è¯¥ç­‰ä»·)** | {len(eq_data)} | {eq_se_time:.1f}s | {eq_eq_time:.1f}s | {eq_correct} | {eq_correct/len(eq_data)*100:.1f}% |\n")
            
            neq_se_time = sum(d['se_time'] for d in neq_data)
            neq_eq_time = sum(d['eq_time'] for d in neq_data)
            f.write(f"| **NEq (åº”è¯¥ä¸ç­‰ä»·)** | {len(neq_data)} | {neq_se_time:.1f}s | {neq_eq_time:.1f}s | {neq_correct} | {neq_correct/len(neq_data)*100:.1f}% |\n")
            f.write("\n")
            
                    
            f.write("## è¯¦ç»†æ—¶é—´ç»Ÿè®¡\n\n")
            f.write("| Benchmark | ç±»å‹ | ç¬¦å·æ‰§è¡Œ(s) | ç­‰ä»·æ€§åˆ†æ(s) | æ€»æ—¶é—´(s) | è·¯å¾„æ•° | æ¯”è¾ƒæ¬¡æ•° | é¢„æµ‹ç»“æœ | å‡†ç¡®æ€§ |\n")
            f.write("|-----------|------|-------------|---------------|-----------|--------|----------|----------|--------|\n")
            
            for d in data:
                benchmark_name = d['path'].replace('benchmarks/', '').replace('/', '_')
                result_icon = "âœ…" if d['is_equivalent'] else "âŒ"
                accuracy_icon = "âœ…" if d['is_correct'] else "âŒ"
                
                f.write(f"| **{benchmark_name}** | {d['type']} | {d['se_time']:.1f} | {d['eq_time']:.1f} | "
                       f"**{d['total_time']:.1f}** | {d['se_paths']} | {d['eq_comparisons']} | "
                       f"{result_icon} | {accuracy_icon} |\n")
            
            f.write("\n")
            
                    
            f.write("## é”™è¯¯é¢„æµ‹åˆ†æ\n\n")
            
            wrong_eq = [d for d in eq_data if not d['is_correct']]
            wrong_neq = [d for d in neq_data if not d['is_correct']]
            
            if wrong_eq:
                f.write("### Eqç¨‹åºè¢«é”™è¯¯é¢„æµ‹ä¸ºä¸ç­‰ä»·:\n\n")
                for d in wrong_eq:
                    f.write(f"- `{d['path']}` (ç¬¦å·æ‰§è¡Œ: {d['se_time']:.1f}s, åˆ†æ: {d['eq_time']:.1f}s)\n")
                f.write("\n")
            
            if wrong_neq:
                f.write("### NEqç¨‹åºè¢«é”™è¯¯é¢„æµ‹ä¸ºç­‰ä»·:\n\n")
                for d in wrong_neq:
                    f.write(f"- `{d['path']}` (ç¬¦å·æ‰§è¡Œ: {d['se_time']:.1f}s, åˆ†æ: {d['eq_time']:.1f}s)\n")
                f.write("\n")
            
                  
            f.write("## æ€§èƒ½åˆ†æ\n\n")
            f.write(f"- **å¹³å‡ç¬¦å·æ‰§è¡Œæ—¶é—´**: {total_se_time/len(data):.1f}ç§’/ç¨‹åºå¯¹\n")
            f.write(f"- **å¹³å‡ç­‰ä»·æ€§åˆ†ææ—¶é—´**: {total_eq_time/len(data):.1f}ç§’/ç¨‹åºå¯¹\n")
            f.write(f"- **å¹³å‡è·¯å¾„æ•°**: {total_paths/len(data):.1f}æ¡/ç¨‹åºå¯¹\n")
            f.write(f"- **å¹³å‡æ¯”è¾ƒæ¬¡æ•°**: {total_comparisons/len(data):.1f}æ¬¡/ç¨‹åºå¯¹\n")
            f.write(f"- **ç¬¦å·æ‰§è¡Œæ•ˆç‡**: {total_paths/total_se_time:.1f}è·¯å¾„/ç§’\n")
            f.write(f"- **ç­‰ä»·æ€§åˆ†ææ•ˆç‡**: {total_comparisons/total_eq_time:.1f}æ¯”è¾ƒ/ç§’\n")
        
        print(f"ğŸ“„ è¯¦ç»†æ—¶é—´ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        return output_file

def main():
    print("ğŸ”§ ç”Ÿæˆbenchmarkæ—¶é—´ç»Ÿè®¡æŠ¥å‘Š...")
    
    generator = TimingReportGenerator()
    
          
    print("ğŸ“Š æ”¶é›†æ—¶é—´æ•°æ®...")
    data = generator.collect_all_timing_data()
    
    print(f"âœ… æ”¶é›†åˆ° {len(data)} ä¸ªç¨‹åºçš„æ•°æ®")
    
          
    report_file = generator.generate_markdown_report(data)
    
    print("ğŸ¯ æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    return report_file

if __name__ == "__main__":
    main() 