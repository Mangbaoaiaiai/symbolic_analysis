                      
"""
å¢å¼ºçš„è·¯å¾„ç­‰ä»·æ€§åˆ†æå™¨ï¼šå››ç±»åˆ¤æ–­æµç¨‹
1. è·¯å¾„çº¦æŸç­‰ä»·ä¸”ç¨‹åºè¾“å‡ºç›¸åŒ â†’ ç­‰ä»·
2. è·¯å¾„çº¦æŸä¸ç­‰ä»·ä½†ç¨‹åºè¾“å‡ºç›¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆçº¦æŸï¼‰
3. è·¯å¾„çº¦æŸç­‰ä»·ä½†ç¨‹åºè¾“å‡ºä¸ç­‰ä»· â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆè¾“å‡ºï¼‰
4. è·¯å¾„çº¦æŸä¸ç­‰ä»·ä¸”ç¨‹åºè¾“å‡ºä¸ç­‰ä»· â†’ ä¸ç­‰ä»·

åŸºäºçº¦æŸè¯­ä¹‰ç­‰ä»·æ€§ã€æ•°ç»„åˆå§‹çŠ¶æ€å’Œæœ€ç»ˆçŠ¶æ€çš„å®Œæ•´è·¯å¾„åˆ†æå™¨
"""

import re
import z3
from z3 import *
import glob
import time
import datetime
import json
from itertools import combinations
from collections import defaultdict

class ArrayStateComparator:
    """æ•°ç»„çŠ¶æ€æ¯”è¾ƒå™¨"""
    
    def __init__(self):
        pass
        
    def parse_array_state(self, content):
        """ä»è·¯å¾„æ–‡ä»¶å†…å®¹ä¸­è§£ææ•°ç»„çŠ¶æ€ä¿¡æ¯"""
        array_initial = {}
        array_final = {}
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            
                     
            if line.startswith('; æ•°ç»„åˆå§‹å€¼:'):
                try:
                    array_str = line.split(':', 1)[1].strip()
                    array_initial = eval(array_str)                                
                except:
                    pass
                    
                     
            elif line.startswith('; æ•°ç»„æœ€ç»ˆå€¼:'):
                try:
                    array_str = line.split(':', 1)[1].strip()
                    array_final = eval(array_str)                                
                except:
                    pass
                    
        return array_initial, array_final
    
    def compare_array_states(self, state1, state2):
        """æ¯”è¾ƒä¸¤ä¸ªæ•°ç»„çŠ¶æ€æ˜¯å¦ç›¸åŒ"""
        if not state1 and not state2:
            return True, "both_empty"
            
        if not state1 or not state2:
            return False, "one_empty"
            
                
        if set(state1.keys()) != set(state2.keys()):
            return False, f"different_arrays: {set(state1.keys())} vs {set(state2.keys())}"
            
                   
        for array_name in state1.keys():
            arr1 = state1[array_name]
            arr2 = state2[array_name]
            
            if set(arr1.keys()) != set(arr2.keys()):
                return False, f"different_indices_in_{array_name}: {set(arr1.keys())} vs {set(arr2.keys())}"
                
            for idx in arr1.keys():
                if arr1[idx] != arr2[idx]:
                    return False, f"different_value_in_{array_name}[{idx}]: {arr1[idx]} vs {arr2[idx]}"
                    
        return True, "identical"

class EnhancedConstraintChecker:
    """å¢å¼ºçš„çº¦æŸç­‰ä»·æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, timeout=30000):
        self.timeout = timeout
        self.constraint_time = 0.0
        self.constraint_call_count = 0
        self.array_time = 0.0
        self.array_call_count = 0
        self.array_comparator = ArrayStateComparator()
        
    def normalize_variable_names(self, formula, var_mapping):
        """æ ‡å‡†åŒ–å˜é‡åï¼Œä½¿ä¸¤ä¸ªå…¬å¼å¯ä»¥æ¯”è¾ƒ"""
        for old_name, new_name in var_mapping.items():
            formula = re.sub(rf'\b{old_name}\b', new_name, formula)
        return formula
    
    def extract_path_info(self, file_path):
        """ä»æ–‡ä»¶ä¸­æå–å®Œæ•´çš„è·¯å¾„ä¿¡æ¯ï¼šçº¦æŸ+æ•°ç»„çŠ¶æ€+ç¨‹åºè¾“å‡º"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
                      
        constraint_lines = [line for line in content.splitlines() if not line.strip().startswith(';')]
        constraint_content = '\n'.join(constraint_lines)
        
                
        variables = {}
        var_pattern = r'\(declare-fun\s+(\w+)\s+\(\)\s+\(_\s+BitVec\s+(\d+)\)\)'
        for match in re.finditer(var_pattern, constraint_content):
            var_name, bit_width = match.groups()
            variables[var_name] = int(bit_width)
        
              
        constraints = []
        constraint_pattern = r'\(assert\s+(.*?)\)(?=\s*(?:\(assert|\(check-sat|$))'
        for match in re.finditer(constraint_pattern, constraint_content, re.DOTALL):
            constraint = match.group(1).strip()
            constraints.append(constraint)
        
                
        array_initial, array_final = self.array_comparator.parse_array_state(content)
        
                   
        program_output = ""
        lines = content.split("\n")
        for i, line in enumerate(lines):
            if line.strip().startswith("; ç¨‹åºè¾“å‡º:"):
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if next_line and not next_line.startswith(";"):
                        program_output = next_line
                        break
        return {
            'variables': variables,
            'constraints': constraints,
            'array_initial': array_initial,
            'array_final': array_final,
            'program_output': program_output
        }
    
    def create_variable_mapping(self, vars1, vars2):
        """åˆ›å»ºå˜é‡æ˜ å°„ï¼Œå°†ä¸¤ç»„å˜é‡å¯¹åº”èµ·æ¥"""
        mapping = {}
        
                      
        scanf_vars1 = [(name, self.extract_scanf_index(name)) for name in vars1.keys() if 'scanf' in name]
        scanf_vars2 = [(name, self.extract_scanf_index(name)) for name in vars2.keys() if 'scanf' in name]
        
               
        scanf_vars1.sort(key=lambda x: x[1])
        scanf_vars2.sort(key=lambda x: x[1])
        
              
        for (name1, idx1), (name2, idx2) in zip(scanf_vars1, scanf_vars2):
            mapping[name1] = name2
        
        return mapping
    
    def extract_scanf_index(self, var_name):
        """ä»scanfå˜é‡åä¸­æå–ç´¢å¼•"""
        match = re.search(r'scanf_(\d+)', var_name)
        return int(match.group(1)) if match else 0
    
    def check_constraint_equivalence(self, constraints1, constraints2, vars1, vars2, var_mapping):
        """æ£€æŸ¥ä¸¤ç»„çº¦æŸæ˜¯å¦é€»è¾‘ç­‰ä»·"""
        start_time = time.time()
        
        solver = Solver()
        solver.set("timeout", self.timeout)
        
        try:
                      
            smt_formula1 = self.build_smt_formula(vars1, constraints1)
            smt_formula2 = self.build_smt_formula(vars2, constraints2, var_mapping)
            
                  
            F1 = parse_smt2_string(smt_formula1)
            F2 = parse_smt2_string(smt_formula2)
            
                     
            formula1 = And(*F1) if len(F1) > 1 else F1[0] if F1 else BoolVal(True)
            formula2 = And(*F2) if len(F2) > 1 else F2[0] if F2 else BoolVal(True)
            
                                              
            equivalence_check = Or(
                And(formula1, Not(formula2)),
                And(Not(formula1), formula2)
            )
            
            solver.add(equivalence_check)
            result = solver.check()
            
            solve_time = time.time() - start_time
            
            if result == unsat:
                return "equivalent", {"solve_time": solve_time}
            elif result == sat:
                model = solver.model()
                return "not_equivalent", {"model": str(model), "solve_time": solve_time}
            else:
                return "unknown", {"solve_time": solve_time}
                
        except Exception as e:
            solve_time = time.time() - start_time
            return "error", {"error": str(e), "solve_time": solve_time}
    
    def build_smt_formula(self, variables, constraints, var_mapping=None):
        """æ„å»ºå®Œæ•´çš„SMTå…¬å¼"""
                
        if var_mapping:
            mapped_variables = {}
            mapped_constraints = []
            
            for old_name, bit_width in variables.items():
                new_name = var_mapping.get(old_name, old_name)
                mapped_variables[new_name] = bit_width
            
            for constraint in constraints:
                mapped_constraint = constraint
                for old_name, new_name in var_mapping.items():
                    mapped_constraint = re.sub(rf'\b{old_name}\b', new_name, mapped_constraint)
                mapped_constraints.append(mapped_constraint)
            
            variables = mapped_variables
            constraints = mapped_constraints
        
                        
        formula_parts = ["(set-logic QF_BV)"]
        
                
        for var_name, bit_width in variables.items():
            formula_parts.append(f"(declare-fun {var_name} () (_ BitVec {bit_width}))")
        
              
        for constraint in constraints:
            formula_parts.append(f"(assert {constraint})")
        
        formula_parts.append("(check-sat)")
        
        return '\n'.join(formula_parts)

class EnhancedPathAnalyzer:
    """å¢å¼ºçš„è·¯å¾„åˆ†æå™¨ - æ”¯æŒå››ç±»åˆ¤æ–­"""
    
    def __init__(self):
        self.checker = EnhancedConstraintChecker()
        self.analysis_start_time = None
        self.analysis_end_time = None
        self.detailed_timing = []
        self.symbolic_execution_time = 0.0           
        
    def set_symbolic_execution_time(self, se_time):
        """è®¾ç½®ç¬¦å·æ‰§è¡Œæ—¶é—´ï¼ˆä»å¤–éƒ¨ä¼ å…¥ï¼‰"""
        self.symbolic_execution_time = se_time
        
    def analyze_program_equivalence(self, file_prefix1, file_prefix2):
        """åˆ†æä¸¤ä¸ªç¨‹åºçš„å®Œæ•´ç­‰ä»·æ€§"""
        self.analysis_start_time = time.time()
        print(f"å¼€å§‹ç¨‹åºç­‰ä»·æ€§åˆ†æ: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
                  
        files1 = sorted(glob.glob(f"{file_prefix1}*.txt"))
        files2 = sorted(glob.glob(f"{file_prefix2}*.txt"))
        
        print(f"ç¨‹åº1è·¯å¾„æ•°: {len(files1)}")
        print(f"ç¨‹åº2è·¯å¾„æ•°: {len(files2)}")
        
                
        load_start = time.time()
        paths1 = []
        paths2 = []
        
        print("æ­£åœ¨åŠ è½½ç¨‹åº1çš„è·¯å¾„ä¿¡æ¯...")
        for file_path in files1:
            try:
                path_info = self.checker.extract_path_info(file_path)
                path_info['file'] = file_path
                paths1.append(path_info)
            except Exception as e:
                print(f"  âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        print("æ­£åœ¨åŠ è½½ç¨‹åº2çš„è·¯å¾„ä¿¡æ¯...")
        for file_path in files2:
            try:
                path_info = self.checker.extract_path_info(file_path)
                path_info['file'] = file_path
                paths2.append(path_info)
            except Exception as e:
                print(f"  âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        load_time = time.time() - load_start
        print(f"æ–‡ä»¶åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.3f} ç§’")
        print(f"æˆåŠŸåŠ è½½è·¯å¾„: {len(paths1)} vs {len(paths2)}")
        
                   
        comparison_start = time.time()
        results = self.find_equivalent_paths_four_categories(paths1, paths2)
        comparison_time = time.time() - comparison_start
        
        self.analysis_end_time = time.time()
        total_time = self.analysis_end_time - self.analysis_start_time
        
                
        results['timing_info'] = {
            'total_time': total_time,
            'load_time': load_time,
            'comparison_time': comparison_time,
            'symbolic_execution_time': self.symbolic_execution_time,
            'constraint_total_time': self.checker.constraint_time,
            'constraint_call_count': self.checker.constraint_call_count,
            'constraint_avg_time': self.checker.constraint_time / max(1, self.checker.constraint_call_count),
            'array_total_time': self.checker.array_time,
            'array_call_count': self.checker.array_call_count,
            'array_avg_time': self.checker.array_time / max(1, self.checker.array_call_count),
            'detailed_timing': self.detailed_timing,
            'start_time': datetime.datetime.fromtimestamp(self.analysis_start_time).strftime('%Y-%m-%d %H:%M:%S'),
            'end_time': datetime.datetime.fromtimestamp(self.analysis_end_time).strftime('%Y-%m-%d %H:%M:%S')
        }
        
                
        print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
        print(f"  ç¬¦å·æ‰§è¡Œæ—¶é—´: {self.symbolic_execution_time:.3f} ç§’")
        print(f"  æ–‡ä»¶åŠ è½½æ—¶é—´: {load_time:.3f} ç§’")
        print(f"  è·¯å¾„æ¯”è¾ƒæ—¶é—´: {comparison_time:.3f} ç§’")
        print(f"    - SMTçº¦æŸéªŒè¯: {self.checker.constraint_time:.3f} ç§’ ({self.checker.constraint_call_count} æ¬¡è°ƒç”¨)")
        print(f"    - æ•°ç»„çŠ¶æ€æ¯”è¾ƒ: {self.checker.array_time:.3f} ç§’ ({self.checker.array_call_count} æ¬¡è°ƒç”¨)")
        print(f"  æ€»åˆ†ææ—¶é—´: {total_time:.3f} ç§’")
        
        return results
    
    def find_equivalent_paths_four_categories(self, paths1, paths2):
        """ä½¿ç”¨å››ç±»åˆ¤æ–­å¯»æ‰¾ç­‰ä»·è·¯å¾„"""
        results = {
            'equivalent_pairs': [],                         
            'suspicious_constraint_pairs': [],                
            'suspicious_output_pairs': [],                  
            'non_equivalent_pairs': [],                      
            'error_pairs': [],
            'unmatched_paths1': list(range(len(paths1))),
            'unmatched_paths2': list(range(len(paths2))),
            'program_equivalent': False
        }
        
        total_comparisons = len(paths1) * len(paths2)
        current_comparison = 0
        comparison_start_time = time.time()
        
        print(f"\nå¼€å§‹å››ç±»ç­‰ä»·æ€§éªŒè¯ ({total_comparisons} å¯¹æ¯”è¾ƒ):")
        
        for i, path1 in enumerate(paths1):
            path1_matched = False
            
            for j, path2 in enumerate(paths2):
                if j in [pair['path2_index'] for pair in results['equivalent_pairs']]:
                    continue            
                    
                current_comparison += 1
                pair_start_time = time.time()
                
                      
                if current_comparison > 1:
                    elapsed = time.time() - comparison_start_time
                    avg_time = elapsed / (current_comparison - 1)
                    remaining = total_comparisons - current_comparison
                    estimated_remaining = avg_time * remaining
                    print(f"  æ¯”è¾ƒ {i+1}-{j+1} ({current_comparison}/{total_comparisons}, {current_comparison/total_comparisons*100:.1f}%) "
                          f"- é¢„è®¡å‰©ä½™: {estimated_remaining:.1f}s")
                else:
                    print(f"  æ¯”è¾ƒè·¯å¾„ {i+1} vs {j+1}")
                
                           
                constraint_start = time.time()
                constraint_result, constraint_details = self.checker.check_constraint_equivalence(
                    path1['constraints'], path2['constraints'],
                    path1['variables'], path2['variables'],
                    self.checker.create_variable_mapping(path1['variables'], path2['variables'])
                )
                constraint_time = time.time() - constraint_start
                
                            
                output1 = path1.get('program_output', '')
                output2 = path2.get('program_output', '')
                outputs_same = (output1 == output2)
                
                            
                pair_info = {
                    'path1_index': i,
                    'path2_index': j,
                    'path1_file': path1['file'],
                    'path2_file': path2['file'],
                    'constraint_result': constraint_result,
                    'constraint_details': constraint_details,
                    'output1': output1,
                    'output2': output2,
                    'outputs_same': outputs_same,
                    'constraint_time': constraint_time,
                    'comparison_time': time.time() - pair_start_time
                }
                
                if constraint_result == "equivalent" and outputs_same:
                                       
                    results['equivalent_pairs'].append(pair_info)
                    if i in results['unmatched_paths1']:
                        results['unmatched_paths1'].remove(i)
                    if j in results['unmatched_paths2']:
                        results['unmatched_paths2'].remove(j)
                    
                    print(f"    âœ… ç­‰ä»· (çº¦æŸç­‰ä»·+è¾“å‡ºç›¸åŒ) è€—æ—¶: {pair_info['comparison_time']:.3f}s")
                    path1_matched = True
                    break           
                    
                elif constraint_result != "equivalent" and outputs_same:
                                               
                    results['suspicious_constraint_pairs'].append(pair_info)
                    print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ (çº¦æŸä¸ç­‰ä»·+è¾“å‡ºç›¸åŒ) è€—æ—¶: {pair_info['comparison_time']:.3f}s")
                    
                elif constraint_result == "equivalent" and not outputs_same:
                                              
                    results['suspicious_output_pairs'].append(pair_info)
                    print(f"    âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º (çº¦æŸç­‰ä»·+è¾“å‡ºä¸åŒ) è€—æ—¶: {pair_info['comparison_time']:.3f}s")
                    
                else:
                                         
                    results['non_equivalent_pairs'].append(pair_info)
                    print(f"    âŒ ä¸ç­‰ä»· (çº¦æŸä¸ç­‰ä»·+è¾“å‡ºä¸åŒ) è€—æ—¶: {pair_info['comparison_time']:.3f}s")
                
                        
                self.checker.constraint_time += constraint_time
                self.checker.constraint_call_count += 1
                
                        
                timing_detail = {
                    'path1_index': i,
                    'path2_index': j,
                    'total_time': pair_info['comparison_time'],
                    'constraint_time': constraint_time,
                    'result': f"{constraint_result}_{'same_output' if outputs_same else 'diff_output'}"
                }
                self.detailed_timing.append(timing_detail)
            
            if not path1_matched:
                print(f"    âŒ è·¯å¾„ {i+1} æœªæ‰¾åˆ°ç­‰ä»·è·¯å¾„")
        
                 
        results['program_equivalent'] = (len(results['unmatched_paths1']) == 0 and 
                                       len(results['unmatched_paths2']) == 0)
        
        print(f"\nğŸ“Š å››ç±»åˆ†æç»“æœ:")
        print(f"  âœ… ç­‰ä»·è·¯å¾„å¯¹: {len(results['equivalent_pairs'])}")
        print(f"  âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ: {len(results['suspicious_constraint_pairs'])}")
        print(f"  âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º: {len(results['suspicious_output_pairs'])}")
        print(f"  âŒ ä¸ç­‰ä»·è·¯å¾„å¯¹: {len(results['non_equivalent_pairs'])}")
        print(f"  ç¨‹åº1æœªåŒ¹é…è·¯å¾„: {len(results['unmatched_paths1'])}")
        print(f"  ç¨‹åº2æœªåŒ¹é…è·¯å¾„: {len(results['unmatched_paths2'])}")
        print(f"  ç¨‹åºæ•´ä½“ç­‰ä»·æ€§: {'âœ… ç­‰ä»·' if results['program_equivalent'] else 'âŒ ä¸ç­‰ä»·'}")
        
        return results
    
    def generate_comprehensive_report(self, results, output_file="enhanced_equivalence_report.txt"):
        """ç”Ÿæˆè¯¦ç»†çš„ç­‰ä»·æ€§åˆ†ææŠ¥å‘Š"""
        with open(output_file, "w", encoding='utf-8') as f:
            f.write("å¢å¼ºçš„ç¨‹åºç­‰ä»·æ€§åˆ†ææŠ¥å‘Šï¼ˆå››ç±»åˆ¤æ–­ï¼‰\n")
            f.write("=" * 60 + "\n\n")
            
                  
            f.write("ğŸ“‹ æ€»ä½“ç»“è®º:\n")
            f.write("-" * 30 + "\n")
            equivalence_status = "âœ… ç­‰ä»·" if results['program_equivalent'] else "âŒ ä¸ç­‰ä»·"
            f.write(f"ç¨‹åºç­‰ä»·æ€§: {equivalence_status}\n\n")
            
                  
            f.write("ğŸ“Š å››ç±»åˆ†æç»Ÿè®¡:\n")
            f.write("-" * 30 + "\n")
            f.write(f"âœ… ç­‰ä»·è·¯å¾„å¯¹: {len(results['equivalent_pairs'])}\n")
            f.write(f"âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ: {len(results['suspicious_constraint_pairs'])}\n")
            f.write(f"âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º: {len(results['suspicious_output_pairs'])}\n")
            f.write(f"âŒ ä¸ç­‰ä»·è·¯å¾„å¯¹: {len(results['non_equivalent_pairs'])}\n")
            f.write(f"ç¨‹åº1æœªåŒ¹é…è·¯å¾„: {len(results['unmatched_paths1'])}\n")
            f.write(f"ç¨‹åº2æœªåŒ¹é…è·¯å¾„: {len(results['unmatched_paths2'])}\n\n")
            
                  
            if 'timing_info' in results:
                timing = results['timing_info']
                f.write("â±ï¸  æ—¶é—´ç»Ÿè®¡:\n")
                f.write("-" * 30 + "\n")
                f.write(f"åˆ†æå¼€å§‹æ—¶é—´: {timing['start_time']}\n")
                f.write(f"åˆ†æç»“æŸæ—¶é—´: {timing['end_time']}\n")
                f.write(f"æ€»åˆ†ææ—¶é—´: {timing['total_time']:.3f} ç§’\n")
                f.write(f"  - ç¬¦å·æ‰§è¡Œæ—¶é—´: {timing['symbolic_execution_time']:.3f} ç§’\n")
                f.write(f"  - æ–‡ä»¶åŠ è½½æ—¶é—´: {timing['load_time']:.3f} ç§’\n")
                f.write(f"  - è·¯å¾„æ¯”è¾ƒæ—¶é—´: {timing['comparison_time']:.3f} ç§’\n")
                f.write(f"    * SMTçº¦æŸéªŒè¯: {timing['constraint_total_time']:.3f} ç§’ ({timing['constraint_call_count']} æ¬¡)\n")
                f.write(f"    * æ•°ç»„çŠ¶æ€æ¯”è¾ƒ: {timing['array_total_time']:.3f} ç§’ ({timing['array_call_count']} æ¬¡)\n")
                f.write(f"å¹³å‡SMTæ±‚è§£æ—¶é—´: {timing['constraint_avg_time']:.3f} ç§’\n")
                f.write(f"å¹³å‡æ•°ç»„æ¯”è¾ƒæ—¶é—´: {timing['array_avg_time']:.3f} ç§’\n\n")
            
                     
            if results['equivalent_pairs']:
                f.write("âœ… ç­‰ä»·è·¯å¾„å¯¹:\n")
                f.write("-" * 30 + "\n")
                for idx, pair in enumerate(results['equivalent_pairs'], 1):
                    f.write(f"{idx}. è·¯å¾„ {pair['path1_index']+1} <-> è·¯å¾„ {pair['path2_index']+1}\n")
                    f.write(f"   æ–‡ä»¶1: {pair['path1_file']}\n")
                    f.write(f"   æ–‡ä»¶2: {pair['path2_file']}\n")
                    f.write(f"   çº¦æŸç»“æœ: {pair['constraint_result']}\n")
                    f.write(f"   è¾“å‡º1: {pair['output1']}\n")
                    f.write(f"   è¾“å‡º2: {pair['output2']}\n")
                    f.write(f"   æ¯”è¾ƒè€—æ—¶: {pair['comparison_time']:.3f} ç§’\n\n")
            
                        
            if results['suspicious_constraint_pairs']:
                f.write("âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ (çº¦æŸä¸ç­‰ä»·ä½†è¾“å‡ºç›¸åŒ):\n")
                f.write("-" * 30 + "\n")
                for idx, pair in enumerate(results['suspicious_constraint_pairs'], 1):
                    f.write(f"{idx}. è·¯å¾„ {pair['path1_index']+1} vs è·¯å¾„ {pair['path2_index']+1}\n")
                    f.write(f"   æ–‡ä»¶1: {pair['path1_file']}\n")
                    f.write(f"   æ–‡ä»¶2: {pair['path2_file']}\n")
                    f.write(f"   çº¦æŸç»“æœ: {pair['constraint_result']}\n")
                    f.write(f"   è¾“å‡º1: {pair['output1']}\n")
                    f.write(f"   è¾“å‡º2: {pair['output2']}\n")
                    f.write(f"   æ¯”è¾ƒè€—æ—¶: {pair['comparison_time']:.3f} ç§’\n\n")
            
                        
            if results['suspicious_output_pairs']:
                f.write("âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º (çº¦æŸç­‰ä»·ä½†è¾“å‡ºä¸åŒ):\n")
                f.write("-" * 30 + "\n")
                for idx, pair in enumerate(results['suspicious_output_pairs'], 1):
                    f.write(f"{idx}. è·¯å¾„ {pair['path1_index']+1} vs è·¯å¾„ {pair['path2_index']+1}\n")
                    f.write(f"   æ–‡ä»¶1: {pair['path1_file']}\n")
                    f.write(f"   æ–‡ä»¶2: {pair['path2_file']}\n")
                    f.write(f"   çº¦æŸç»“æœ: {pair['constraint_result']}\n")
                    f.write(f"   è¾“å‡º1: {pair['output1']}\n")
                    f.write(f"   è¾“å‡º2: {pair['output2']}\n")
                    f.write(f"   æ¯”è¾ƒè€—æ—¶: {pair['comparison_time']:.3f} ç§’\n\n")
            
                      
            if results['non_equivalent_pairs']:
                f.write("âŒ ä¸ç­‰ä»·è·¯å¾„å¯¹:\n")
                f.write("-" * 30 + "\n")
                for idx, pair in enumerate(results['non_equivalent_pairs'], 1):
                    f.write(f"{idx}. è·¯å¾„ {pair['path1_index']+1} vs è·¯å¾„ {pair['path2_index']+1}\n")
                    f.write(f"   æ–‡ä»¶1: {pair['path1_file']}\n")
                    f.write(f"   æ–‡ä»¶2: {pair['path2_file']}\n")
                    f.write(f"   çº¦æŸç»“æœ: {pair['constraint_result']}\n")
                    f.write(f"   è¾“å‡º1: {pair['output1']}\n")
                    f.write(f"   è¾“å‡º2: {pair['output2']}\n")
                    f.write(f"   æ¯”è¾ƒè€—æ—¶: {pair['comparison_time']:.3f} ç§’\n\n")
            
                   
            if results['unmatched_paths1']:
                f.write("âŒ ç¨‹åº1ä¸­çš„æœªåŒ¹é…è·¯å¾„:\n")
                f.write("-" * 30 + "\n")
                for idx in results['unmatched_paths1']:
                    f.write(f"  è·¯å¾„ {idx+1}\n")
                f.write("\n")
            
            if results['unmatched_paths2']:
                f.write("âŒ ç¨‹åº2ä¸­çš„æœªåŒ¹é…è·¯å¾„:\n")
                f.write("-" * 30 + "\n")
                for idx in results['unmatched_paths2']:
                    f.write(f"  è·¯å¾„ {idx+1}\n")
                f.write("\n")
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¢å¼ºçš„ç¨‹åºç­‰ä»·æ€§åˆ†æå™¨ï¼šå››ç±»åˆ¤æ–­æµç¨‹')
    parser.add_argument('prefix1', help='ç¬¬ä¸€ä¸ªç¨‹åºè·¯å¾„æ–‡ä»¶çš„å‰ç¼€')
    parser.add_argument('prefix2', help='ç¬¬äºŒä¸ªç¨‹åºè·¯å¾„æ–‡ä»¶çš„å‰ç¼€')
    parser.add_argument('--output', default='enhanced_equivalence_report.txt', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶')
    parser.add_argument('--timeout', type=int, default=30000, help='Z3æ±‚è§£å™¨è¶…æ—¶æ—¶é—´(æ¯«ç§’)')
    parser.add_argument('--se-time', type=float, default=0.0, help='ç¬¦å·æ‰§è¡Œæ—¶é—´(ç§’)ï¼Œç”¨äºç»Ÿè®¡')
    
    args = parser.parse_args()
    
    analyzer = EnhancedPathAnalyzer()
    analyzer.checker.timeout = args.timeout
    analyzer.set_symbolic_execution_time(args.se_time)
    
    print("ğŸš€ å¼€å§‹å¢å¼ºçš„ç¨‹åºç­‰ä»·æ€§åˆ†æ...")
    print("=" * 60)
    print("å››ç±»åˆ¤æ–­æµç¨‹:")
    print("  1ï¸âƒ£  çº¦æŸç­‰ä»·ä¸”è¾“å‡ºç›¸åŒ â†’ ç­‰ä»·")
    print("  2ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä½†è¾“å‡ºç›¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆçº¦æŸï¼‰")
    print("  3ï¸âƒ£  çº¦æŸç­‰ä»·ä½†è¾“å‡ºä¸åŒ â†’ ç–‘ä¼¼ä¸ç­‰ä»·ï¼ˆè¾“å‡ºï¼‰")
    print("  4ï¸âƒ£  çº¦æŸä¸ç­‰ä»·ä¸”è¾“å‡ºä¸åŒ â†’ ä¸ç­‰ä»·")
    print("=" * 60)
    
    results = analyzer.analyze_program_equivalence(args.prefix1, args.prefix2)
    
    analyzer.generate_comprehensive_report(results, args.output)
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æœ€ç»ˆåˆ†æç»“æœ:")
    print(f"  ç¨‹åºç­‰ä»·æ€§: {'âœ… ç­‰ä»·' if results['program_equivalent'] else 'âŒ ä¸ç­‰ä»·'}")
    print(f"  âœ… ç­‰ä»·è·¯å¾„å¯¹: {len(results['equivalent_pairs'])}")
    print(f"  âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-çº¦æŸ: {len(results['suspicious_constraint_pairs'])}")
    print(f"  âš ï¸  ç–‘ä¼¼ä¸ç­‰ä»·-è¾“å‡º: {len(results['suspicious_output_pairs'])}")
    print(f"  âŒ ä¸ç­‰ä»·è·¯å¾„å¯¹: {len(results['non_equivalent_pairs'])}")
    print(f"  æ€»åˆ†æè·¯å¾„å¯¹: {len(results['equivalent_pairs']) + len(results['suspicious_constraint_pairs']) + len(results['suspicious_output_pairs']) + len(results['non_equivalent_pairs'])}")
    
    if 'timing_info' in results:
        timing = results['timing_info']
        print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»è€—æ—¶: {timing['total_time']:.3f} ç§’")
        print(f"  ç¬¦å·æ‰§è¡Œ: {timing['symbolic_execution_time']:.3f} ç§’")
        print(f"  SMTæ±‚è§£: {timing['constraint_total_time']:.3f} ç§’ ({timing['constraint_call_count']} æ¬¡)")
        print(f"  æ•°ç»„æ¯”è¾ƒ: {timing['array_total_time']:.3f} ç§’ ({timing['array_call_count']} æ¬¡)")
    
    print("=" * 60)
    print("âœ… åˆ†æå®Œæˆï¼è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶ã€‚")

if __name__ == "__main__":
    main()
