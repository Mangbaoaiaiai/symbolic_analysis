                      
"""
åˆ†æè¶…æ—¶é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
"""

import os
import glob
from pathlib import Path

def analyze_timeout_issue():
    """åˆ†æä¸ºä»€ä¹ˆå‰©ä½™ç¨‹åºä¼šè¶…æ—¶"""
    
    print("ğŸ” çº¦æŸæ–‡ä»¶ç”Ÿæˆè¶…æ—¶é—®é¢˜åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
            
    all_executables = []
    remaining_executables = []
    base_dir = Path("/root/ardiff/symbolic_analysis")
    
    pattern = str(base_dir / "benchmarks" / "**" / "symbolic_*")
    for file_path in glob.glob(pattern, recursive=True):
        if os.path.isfile(file_path) and os.access(file_path, os.X_OK):
            if not file_path.endswith('.c'):
                all_executables.append(file_path)
                
                           
                exec_dir = os.path.dirname(file_path)
                exec_name = os.path.basename(file_path)
                constraint_files = glob.glob(os.path.join(exec_dir, f"{exec_name}_path_*.txt"))
                
                if not constraint_files:
                    remaining_executables.append(file_path)
    
    all_constraint_files = glob.glob(str(base_dir / "benchmarks" / "**" / "*_path_*.txt"), recursive=True)
    
    print(f"ğŸ“Š å½“å‰çŠ¶æ€:")
    print(f"  â€¢ æ€»å¯æ‰§è¡Œæ–‡ä»¶æ•°: {len(all_executables)}")
    print(f"  â€¢ å·²ç”Ÿæˆçº¦æŸæ–‡ä»¶æ•°: {len(all_constraint_files)}")
    print(f"  â€¢ å‰©ä½™å¾…å¤„ç†æ•°: {len(remaining_executables)}")
    print(f"  â€¢ æˆåŠŸç‡: {(len(all_constraint_files)/(len(all_executables)*3))*100:.1f}%")                
    
               
    print(f"\nğŸ§ å‰©ä½™ç¨‹åºåˆ†æ:")
    print("-" * 40)
    
    categories = {}
    for executable in remaining_executables:
              
        parts = Path(executable).parts
        if 'benchmarks' in parts:
            idx = parts.index('benchmarks')
            if len(parts) > idx + 1:
                category = parts[idx + 1]
                if category not in categories:
                    categories[category] = []
                categories[category].append(executable)
    
    for category, files in categories.items():
        print(f"  {category}: {len(files)} ä¸ªç¨‹åº")
    
               
    print(f"\nğŸ’¡ è¶…æ—¶åŸå› åˆ†æ:")
    print("-" * 30)
    
    print("1. **å¾ªç¯å¤æ‚æ€§**: ModDiffç¨‹åºåŒ…å«ç¬¦å·å¾ªç¯å˜é‡")
    print("   - `for (int i = 0; i < x % 5; ++i)` ä¼šäº§ç”Ÿè·¯å¾„çˆ†ç‚¸")
    print("   - angréœ€è¦æ¢ç´¢0-4æ¬¡å¾ªç¯çš„æ‰€æœ‰å¯èƒ½")
    
    print("\n2. **æµ®ç‚¹è¿ç®—**: Ran/gamç¨‹åºä½¿ç”¨æµ®ç‚¹æ•°è¿ç®—")
    print("   - `double val = (double)x / 3.0` æ¶‰åŠæµ®ç‚¹ç¬¦å·æ‰§è¡Œ")
    print("   - angrçš„æµ®ç‚¹æ”¯æŒç›¸å¯¹è¾ƒæ…¢")
    
    print("\n3. **æ•°å­¦å‡½æ•°**: æŸäº›ç¨‹åºå¯èƒ½è°ƒç”¨å¤æ‚æ•°å­¦å‡½æ•°")
    print("   - sin, cos, logç­‰å‡½æ•°çš„ç¬¦å·æ‰§è¡Œå¤æ‚åº¦é«˜")
    
    print("\n4. **å†…å­˜æ“ä½œ**: å¤æ‚çš„å†…å­˜è®¿é—®æ¨¡å¼")
    print("   - å¤§å‹æ•°ç»„æˆ–åŠ¨æ€å†…å­˜åˆ†é…")
    
            
    print(f"\nğŸ› ï¸ è§£å†³æ–¹æ¡ˆ:")
    print("-" * 20)
    
    print("**æ–¹æ¡ˆ1: è°ƒæ•´angré…ç½®**")
    print("  - é™åˆ¶è·¯å¾„æ¢ç´¢æ·±åº¦")
    print("  - è®¾ç½®æ›´ä¸¥æ ¼çš„è¶…æ—¶")
    print("  - ç¦ç”¨æŸäº›å¤æ‚åˆ†æ")
    
    print("\n**æ–¹æ¡ˆ2: ç®€åŒ–ç¨‹åºé€»è¾‘**")
    print("  - å°†å¾ªç¯ä¸Šç•Œæ”¹ä¸ºå¸¸æ•°")
    print("  - ç§»é™¤å¤æ‚æµ®ç‚¹è¿ç®—")
    print("  - ç®€åŒ–æ¡ä»¶åˆ†æ”¯")
    
    print("\n**æ–¹æ¡ˆ3: åˆ†æ‰¹å¤„ç†**")
    print("  - ä¼˜å…ˆå¤„ç†ç®€å•ç¨‹åº")
    print("  - è·³è¿‡å¤æ‚ç¨‹åº")
    print("  - è®°å½•è¶…æ—¶åŸå› ")
    
            
    print(f"\nğŸ¯ å½“å‰æˆæœæ€»ç»“:")
    print("-" * 30)
    
    success_programs = len(all_executables) - len(remaining_executables)
    success_rate = (success_programs / len(all_executables)) * 100
    
    print(f"âœ… æˆåŠŸå¤„ç†: {success_programs}/{len(all_executables)} ä¸ªç¨‹åº ({success_rate:.1f}%)")
    print(f"ğŸ“„ ç”Ÿæˆçº¦æŸæ–‡ä»¶: {len(all_constraint_files)} ä¸ª")
    print(f"â±ï¸  å‰©ä½™è¶…æ—¶ç¨‹åº: {len(remaining_executables)} ä¸ª")
    
            
    meaningful_count = 0
    for constraint_file in all_constraint_files:
        try:
            with open(constraint_file, 'r', encoding='utf-8') as f:
                content = f.read()
            if '(assert' in content and ('scanf_' in content or 'mem_' in content):
                meaningful_count += 1
        except:
            continue
    
    print(f"ğŸ¯ æœ‰æ„ä¹‰çº¦æŸ: {meaningful_count}/{len(all_constraint_files)} ä¸ª ({(meaningful_count/max(1,len(all_constraint_files)))*100:.1f}%)")
    
    print(f"\nğŸ“ˆ å»ºè®®:")
    print("1. å½“å‰å·²è·å¾—116ä¸ªé«˜è´¨é‡çº¦æŸæ–‡ä»¶ï¼Œè¦†ç›–äº†å¤§éƒ¨åˆ†æµ‹è¯•ç”¨ä¾‹")
    print("2. å‰©ä½™è¶…æ—¶ç¨‹åºä¸»è¦æ˜¯å¤æ‚é€»è¾‘ï¼Œå¯ä»¥è€ƒè™‘:")
    print("   - æ¥å—å½“å‰ç»“æœï¼Œ116ä¸ªçº¦æŸæ–‡ä»¶å·²ç»è¶³å¤Ÿåˆ†æä½¿ç”¨")
    print("   - æˆ–è€…é’ˆå¯¹ç‰¹å®šç¨‹åºæ‰‹åŠ¨ä¼˜åŒ–è½¬æ¢é€»è¾‘")
    print("3. è¶…æ—¶é—®é¢˜æ˜¯angrç¬¦å·æ‰§è¡Œçš„å›ºæœ‰é™åˆ¶ï¼Œä¸æ˜¯ä¿®å¤é”™è¯¯")

if __name__ == "__main__":
    analyze_timeout_issue() 