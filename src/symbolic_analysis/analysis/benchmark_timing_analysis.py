                      
"""
Benchmarkæ—¶é—´åˆ†æè„šæœ¬

æ•´ç†å’Œç»Ÿè®¡æ¯ä¸ªbenchmarkéªŒè¯è¿‡ç¨‹çš„ç”¨æ—¶ï¼ŒåŒ…æ‹¬ï¼š
1. ç¬¦å·æ‰§è¡Œæ—¶é—´
2. ç­‰ä»·æ€§åˆ†ææ—¶é—´
3. æ€»ä½“ç»Ÿè®¡
"""

import json
import glob
import re
import os
from collections import defaultdict
from datetime import datetime

class BenchmarkTimingAnalyzer:
    def __init__(self):
        self.equivalence_data = None
        self.symbolic_execution_data = {}
        self.combined_stats = defaultdict(dict)
    
    def load_equivalence_data(self):
        """åŠ è½½ç­‰ä»·æ€§åˆ†ææ•°æ®"""
        try:
            with open('batch_equivalence_analysis_data.json', 'r', encoding='utf-8') as f:
                self.equivalence_data = json.load(f)
            print("âœ… æˆåŠŸåŠ è½½ç­‰ä»·æ€§åˆ†ææ•°æ®")
            return True
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°ç­‰ä»·æ€§åˆ†ææ•°æ®æ–‡ä»¶")
            return False
    
    def load_symbolic_execution_data(self):
        """åŠ è½½ç¬¦å·æ‰§è¡Œæ•°æ®"""
        try:
                            
            if os.path.exists('batch_symbolic_execution_data.json'):
                with open('batch_symbolic_execution_data.json', 'r', encoding='utf-8') as f:
                    se_json = json.load(f)
                self.parse_symbolic_execution_json(se_json)
                print("âœ… æˆåŠŸåŠ è½½ç¬¦å·æ‰§è¡ŒJSONæ•°æ®")
                return True
            
                                   
            se_files = glob.glob("*symbolic_execution_report.txt")
            if not se_files:
                print("âš ï¸  æœªæ‰¾åˆ°ç¬¦å·æ‰§è¡Œæ•°æ®æ–‡ä»¶")
                return False
            
            for file in se_files:
                self.parse_symbolic_execution_file(file)
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(se_files)} ä¸ªç¬¦å·æ‰§è¡ŒæŠ¥å‘Š")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½ç¬¦å·æ‰§è¡Œæ•°æ®å¤±è´¥: {e}")
            return False
    
    def parse_symbolic_execution_json(self, se_json):
        """è§£æç¬¦å·æ‰§è¡ŒJSONæ•°æ®"""
        try:
            for benchmark, binaries in se_json['results'].items():
                                                               
                benchmark_name = benchmark.replace('benchmark_temp_', '')
                
                                   
                total_time = 0.0
                total_paths = 0
                optimization_levels = {}
                
                for binary_data in binaries:
                    binary_name = binary_data['binary_name']
                                              
                    if '_' in binary_name:
                        opt_level = binary_name.split('_')[-1]
                        optimization_levels[opt_level] = {
                            'execution_time': binary_data['execution_time'],
                            'paths_found': binary_data['paths_found'],
                            'setup_time': binary_data.get('setup_time', 0),
                            'exploration_time': binary_data.get('exploration_time', 0),
                            'analysis_time': binary_data.get('analysis_time', 0)
                        }
                    
                    total_time += binary_data['execution_time']
                    total_paths += binary_data['paths_found']
                
                        
                avg_time = total_time / len(binaries) if binaries else 0
                
                self.symbolic_execution_data[benchmark_name] = {
                    'total_execution_time': total_time,
                    'average_execution_time': avg_time,
                    'total_paths_found': total_paths,
                    'optimization_levels': optimization_levels,
                    'binary_count': len(binaries)
                }
                
        except Exception as e:
            print(f"âš ï¸  è§£æç¬¦å·æ‰§è¡ŒJSONæ•°æ®å¤±è´¥: {e}")
    
    def parse_symbolic_execution_file(self, filename):
        """è§£æç¬¦å·æ‰§è¡ŒæŠ¥å‘Šæ–‡ä»¶"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                content = f.read()
            
                         
            programs = re.findall(r'ç¨‹åº: (.+?)\n', content)
            execution_times = re.findall(r'æ‰§è¡Œæ—¶é—´: ([0-9.]+) ç§’', content)
            
                         
            sections = content.split('=' * 60)
            for section in sections:
                if 'åˆ†æç»“æœ:' in section and 'ç¨‹åº:' in section:
                    program_match = re.search(r'ç¨‹åº: (.+?)\n', section)
                    time_match = re.search(r'æ‰§è¡Œæ—¶é—´: ([0-9.]+) ç§’', section)
                    paths_match = re.search(r'å‘ç°è·¯å¾„: (\d+)', section)
                    
                    if program_match and time_match:
                        program = program_match.group(1).strip()
                        time = float(time_match.group(1))
                        paths = int(paths_match.group(1)) if paths_match else 0
                        
                        self.symbolic_execution_data[program] = {
                            'execution_time': time,
                            'paths_found': paths,
                            'source_file': filename
                        }
        
        except Exception as e:
            print(f"âš ï¸  è§£æ {filename} å¤±è´¥: {e}")
    
    def combine_timing_data(self):
        """åˆå¹¶ç¬¦å·æ‰§è¡Œå’Œç­‰ä»·æ€§åˆ†æçš„æ—¶é—´æ•°æ®"""
        if not self.equivalence_data:
            return
        

                   
        for program, comparisons in self.equivalence_data['results'].items():
            if program not in self.combined_stats:
                self.combined_stats[program] = {
                    'symbolic_execution_time': 0.0,
                    'equivalence_comparisons': [],
                    'total_equivalence_time': 0.0,
                    'total_paths': 0,
                    'comparison_count': 0
                }
            
            total_eq_time = 0.0
            total_paths = 0
            
            for comparison in comparisons:
                self.combined_stats[program]['equivalence_comparisons'].append({
                    'opt1': comparison['opt1'],
                    'opt2': comparison['opt2'],
                    'time': comparison['execution_time'],
                    'equivalent_pairs': comparison['equivalent_pairs'],
                    'paths_compared': comparison['total_paths_compared']
                })
                total_eq_time += comparison['execution_time']
                total_paths = max(total_paths, comparison['total_paths_compared'])
            
            self.combined_stats[program]['total_equivalence_time'] = total_eq_time
            self.combined_stats[program]['total_paths'] = total_paths
            self.combined_stats[program]['comparison_count'] = len(comparisons)
        
                  
        for program, se_data in self.symbolic_execution_data.items():
                      
            matched_program = None
                      
            if program in self.combined_stats:
                matched_program = program
            else:
                                 
                possible_matches = []
                for combined_program in self.combined_stats.keys():
                    if program in combined_program or combined_program in program:
                        possible_matches.append((combined_program, len(combined_program)))
                                  
                if possible_matches:
                    matched_program = min(possible_matches, key=lambda x: x[1])[0]
            
            if matched_program:
                          
                if 'total_execution_time' in se_data:
                              
                    self.combined_stats[matched_program]['symbolic_execution_time'] = se_data['total_execution_time']
                    self.combined_stats[matched_program]['average_se_time'] = se_data['average_execution_time']
                    self.combined_stats[matched_program]['se_optimization_levels'] = se_data['optimization_levels']
                    self.combined_stats[matched_program]['se_binary_count'] = se_data['binary_count']
                    if se_data['total_paths_found'] > 0:
                        self.combined_stats[matched_program]['total_paths'] = se_data['total_paths_found']
                else:
                            
                    self.combined_stats[matched_program]['symbolic_execution_time'] = se_data['execution_time']
                    if se_data['paths_found'] > 0:
                        self.combined_stats[matched_program]['total_paths'] = se_data['paths_found']
    
    def generate_timing_report(self):
        """ç”Ÿæˆæ—¶é—´ç»Ÿè®¡æŠ¥å‘Š"""
        if not self.combined_stats:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ—¶é—´æ•°æ®")
            return
        
        print("\nğŸ• BenchmarkéªŒè¯è¿‡ç¨‹æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 80)
        
              
        total_se_time = sum(stats['symbolic_execution_time'] for stats in self.combined_stats.values())
        total_eq_time = sum(stats['total_equivalence_time'] for stats in self.combined_stats.values())
        total_programs = len(self.combined_stats)
        total_comparisons = sum(stats['comparison_count'] for stats in self.combined_stats.values())
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  åˆ†æç¨‹åºæ•°: {total_programs}")
        print(f"  ç­‰ä»·æ€§æ¯”è¾ƒæ¬¡æ•°: {total_comparisons}")
        print(f"  ç¬¦å·æ‰§è¡Œæ€»æ—¶é—´: {total_se_time:.2f} ç§’")
        print(f"  ç­‰ä»·æ€§åˆ†ææ€»æ—¶é—´: {total_eq_time:.2f} ç§’")
        print(f"  éªŒè¯æ€»æ—¶é—´: {total_se_time + total_eq_time:.2f} ç§’")
        
                   
        print(f"\nğŸ“‹ å„ç¨‹åºè¯¦ç»†ç»Ÿè®¡:")
        print("-" * 80)
        print(f"{'ç¨‹åºå':<12} {'ç¬¦å·æ‰§è¡Œ':<10} {'ç­‰ä»·æ€§åˆ†æ':<12} {'æ€»æ—¶é—´':<10} {'è·¯å¾„æ•°':<8} {'æ¯”è¾ƒæ¬¡æ•°':<8}")
        print("-" * 80)
        
        sorted_programs = sorted(self.combined_stats.items(), 
                               key=lambda x: x[1]['symbolic_execution_time'] + x[1]['total_equivalence_time'], 
                               reverse=True)
        
        for program, stats in sorted_programs:
            se_time = stats['symbolic_execution_time']
            eq_time = stats['total_equivalence_time']
            total_time = se_time + eq_time
            paths = stats['total_paths']
            comparisons = stats['comparison_count']
            
            print(f"{program:<12} {se_time:<10.2f} {eq_time:<12.2f} {total_time:<10.2f} {paths:<8} {comparisons:<8}")
        
                
        print(f"\nâš¡ æ—¶é—´åˆ†å¸ƒåˆ†æ:")
        se_percentage = (total_se_time / (total_se_time + total_eq_time)) * 100 if (total_se_time + total_eq_time) > 0 else 0
        eq_percentage = (total_eq_time / (total_se_time + total_eq_time)) * 100 if (total_se_time + total_eq_time) > 0 else 0
        
        print(f"  ç¬¦å·æ‰§è¡Œå æ¯”: {se_percentage:.1f}%")
        print(f"  ç­‰ä»·æ€§åˆ†æå æ¯”: {eq_percentage:.1f}%")
        
        avg_se_time = total_se_time / total_programs if total_programs > 0 else 0
        avg_eq_time = total_eq_time / total_comparisons if total_comparisons > 0 else 0
        
        print(f"  å¹³å‡ç¬¦å·æ‰§è¡Œæ—¶é—´: {avg_se_time:.2f} ç§’/ç¨‹åº")
        print(f"  å¹³å‡ç­‰ä»·æ€§åˆ†ææ—¶é—´: {avg_eq_time:.2f} ç§’/æ¯”è¾ƒ")
    
    def generate_detailed_breakdown(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ—¶é—´åˆ†è§£æŠ¥å‘Š"""
        print(f"\nğŸ” è¯¦ç»†æ—¶é—´åˆ†è§£:")
        print("=" * 80)
        
        for program, stats in sorted(self.combined_stats.items()):
            print(f"\nğŸ“ {program}:")
            print(f"  ç¬¦å·æ‰§è¡Œæ€»æ—¶é—´: {stats['symbolic_execution_time']:.2f} ç§’")
            
                            
            if 'se_optimization_levels' in stats:
                print(f"  ç¬¦å·æ‰§è¡Œè¯¦æƒ… ({stats.get('se_binary_count', 0)} ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶):")
                for opt_level, opt_data in stats['se_optimization_levels'].items():
                    print(f"    {opt_level}: {opt_data['execution_time']:.2f}s "
                          f"(è®¾ç½®: {opt_data.get('setup_time', 0):.3f}s, "
                          f"æ¢ç´¢: {opt_data.get('exploration_time', 0):.3f}s, "
                          f"åˆ†æ: {opt_data.get('analysis_time', 0):.3f}s, "
                          f"è·¯å¾„: {opt_data['paths_found']})")
                print(f"    å¹³å‡æ—¶é—´: {stats.get('average_se_time', 0):.2f} ç§’/äºŒè¿›åˆ¶")
            
            print(f"  å‘ç°è·¯å¾„æ€»æ•°: {stats['total_paths']} æ¡")
            print(f"  ç­‰ä»·æ€§æ¯”è¾ƒ ({stats['comparison_count']} æ¬¡):")
            
            for comp in stats['equivalence_comparisons']:
                print(f"    {comp['opt1']} vs {comp['opt2']}: {comp['time']:.3f}s "
                      f"({comp['equivalent_pairs']} ç­‰ä»·å¯¹, {comp['paths_compared']} è·¯å¾„)")
            
            print(f"  ç­‰ä»·æ€§åˆ†ææ€»æ—¶é—´: {stats['total_equivalence_time']:.2f} ç§’")
            total_time = stats['symbolic_execution_time'] + stats['total_equivalence_time']
            print(f"  ğŸ• æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    def save_timing_summary(self):
        """ä¿å­˜æ—¶é—´ç»Ÿè®¡æ‘˜è¦åˆ°æ–‡ä»¶"""
        summary = {
            'generated_time': datetime.now().isoformat(),
            'total_programs': len(self.combined_stats),
            'total_symbolic_execution_time': sum(stats['symbolic_execution_time'] for stats in self.combined_stats.values()),
            'total_equivalence_time': sum(stats['total_equivalence_time'] for stats in self.combined_stats.values()),
            'program_details': dict(self.combined_stats)
        }
        
        with open('benchmark_timing_summary.json', 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ æ—¶é—´ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: benchmark_timing_summary.json")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = BenchmarkTimingAnalyzer()
    
          
    if not analyzer.load_equivalence_data():
        return
    
    analyzer.load_symbolic_execution_data()
    
             
    analyzer.combine_timing_data()
    
          
    analyzer.generate_timing_report()
    analyzer.generate_detailed_breakdown()
    analyzer.save_timing_summary()

if __name__ == "__main__":
    main() 